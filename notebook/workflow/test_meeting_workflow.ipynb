{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Meeting Workflow Test Notebook\n",
    "\n",
    "This notebook tests the WhisperX-based meeting workflow functionality with the MP3 file in `data/test/`."
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T09:58:51.201415Z",
     "start_time": "2026-02-20T09:58:51.189879Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "# .env ÌååÏùº Î°úÎìú\n",
    "dotenv_path = find_dotenv()\n",
    "load_dotenv(dotenv_path, override=True)\n",
    "\n",
    "# ÌïÑÏöîÌïú ÌôòÍ≤Ω Î≥ÄÏàòÎì§ ÌôïÏù∏\n",
    "print(\"Environment Variables:\")\n",
    "print(f\"  OPENAI_API_KEY: {'Set' if os.getenv('OPENAI_API_KEY') else 'Not Set'}\")\n",
    "print(f\"  HF_TOKEN: {'Set' if os.getenv('HF_TOKEN') else 'Not Set'}\")\n",
    "print(f\"  WHISPERX_DEVICE: {os.getenv('WHISPERX_DEVICE', 'cpu')}\")\n",
    "print(f\"  WHISPERX_MODEL: {os.getenv('WHISPERX_MODEL', 'large-v2')}\")\n",
    "print(f\"  WHISPERX_LANGUAGE: {os.getenv('WHISPERX_LANGUAGE', 'ko')}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Variables:\n",
      "  OPENAI_API_KEY: Set\n",
      "  HF_TOKEN: Set\n",
      "  WHISPERX_DEVICE: cpu\n",
      "  WHISPERX_MODEL: large-v2\n",
      "  WHISPERX_LANGUAGE: ko\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T09:58:52.403234Z",
     "start_time": "2026-02-20T09:58:52.390572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['PATH'] = '/opt/homebrew/opt/ffmpeg@7/bin:' + os.environ['PATH']\n",
    "\n",
    "import subprocess\n",
    "result = subprocess.run(['which', 'ffmpeg'], capture_output=True, text=True)\n",
    "print(result.stdout)  # /opt/homebrew/opt/ffmpeg@7/bin/ffmpeg ÎÇòÏôÄÏïº Ìï®"
   ],
   "id": "7d51fec8a3a744b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/opt/ffmpeg@7/bin/ffmpeg\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "cell-2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T09:59:00.014044Z",
     "start_time": "2026-02-20T09:58:55.579391Z"
    }
   },
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "import time\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "\n",
    "# Meeting workflow imports\n",
    "from app.agents.workflows.meeting_workflow import (\n",
    "    process_meeting, \n",
    "    process_meeting_stream,\n",
    "    create_meeting_workflow\n",
    ")\n",
    "from app.agents.state import MeetingState\n",
    "from app.agents.nodes.meeting import (\n",
    "    transcribe_audio,\n",
    "    merge_transcript,\n",
    "    generate_minutes\n",
    ")\n",
    "from app.core.config import settings\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"Settings loaded: {type(settings)}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/pyannote/audio/core/io.py:47: UserWarning: \n",
      "torchcodec is not installed correctly so built-in audio decoding will fail. Solutions are:\n",
      "* use audio preloaded in-memory as a {'waveform': (channel, time) torch.Tensor, 'sample_rate': int} dictionary;\n",
      "* fix torchcodec installation. Error message was:\n",
      "\n",
      "Could not load libtorchcodec. Likely causes:\n",
      "          1. FFmpeg is not properly installed in your environment. We support\n",
      "             versions 4, 5, 6, 7, and 8, and we attempt to load libtorchcodec\n",
      "             for each of those versions. Errors for versions not installed on\n",
      "             your system are expected; only the error for your installed FFmpeg\n",
      "             version is relevant. On Windows, ensure you've installed the\n",
      "             \"full-shared\" version which ships DLLs.\n",
      "          2. The PyTorch version (2.8.0) is not compatible with\n",
      "             this version of TorchCodec. Refer to the version compatibility\n",
      "             table:\n",
      "             https://github.com/pytorch/torchcodec?tab=readme-ov-file#installing-torchcodec.\n",
      "          3. Another runtime dependency; see exceptions below.\n",
      "\n",
      "        The following exceptions were raised as we tried to load libtorchcodec:\n",
      "        \n",
      "[start of libtorchcodec loading traceback]\n",
      "FFmpeg version 8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torchcodec/_core/ops.py\", line 57, in load_torchcodec_shared_libraries\n",
      "    torch.ops.load_library(core_library_path)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torch/_ops.py\", line 1478, in load_library\n",
      "    ctypes.CDLL(path)\n",
      "    ~~~~~~~~~~~^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ctypes/__init__.py\", line 390, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "                   ~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "OSError: dlopen(/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torchcodec/libtorchcodec_core8.dylib, 0x0006): Symbol not found: __ZN3c1013MessageLogger6streamEv\n",
      "  Referenced from: <7279B81B-A90C-320A-876B-333758933189> /Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torchcodec/libtorchcodec_core8.dylib\n",
      "  Expected in:     <D1057909-9D16-345A-8B8C-73FA6C3DB62C> /Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torch/lib/libc10.dylib\n",
      "\n",
      "FFmpeg version 7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torchcodec/_core/ops.py\", line 57, in load_torchcodec_shared_libraries\n",
      "    torch.ops.load_library(core_library_path)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torch/_ops.py\", line 1478, in load_library\n",
      "    ctypes.CDLL(path)\n",
      "    ~~~~~~~~~~~^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ctypes/__init__.py\", line 390, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "                   ~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "OSError: dlopen(/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torchcodec/libtorchcodec_core7.dylib, 0x0006): Library not loaded: @rpath/libavutil.59.dylib\n",
      "  Referenced from: <A7E0555C-E19B-3129-B99E-4A3F1A5FEB51> /Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torchcodec/libtorchcodec_core7.dylib\n",
      "  Reason: tried: '/opt/homebrew/opt/ffmpeg/lib/libavutil.59.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/ffmpeg/lib/libavutil.59.dylib' (no such file), '/opt/homebrew/opt/ffmpeg/lib/libavutil.59.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/ffmpeg/lib/libavutil.59.dylib' (no such file), '/opt/homebrew/lib/libavutil.59.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libavutil.59.dylib' (no such file), '/opt/homebrew/lib/libavutil.59.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libavutil.59.dylib' (no such file)\n",
      "\n",
      "FFmpeg version 6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torchcodec/_core/ops.py\", line 57, in load_torchcodec_shared_libraries\n",
      "    torch.ops.load_library(core_library_path)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torch/_ops.py\", line 1478, in load_library\n",
      "    ctypes.CDLL(path)\n",
      "    ~~~~~~~~~~~^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ctypes/__init__.py\", line 390, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "                   ~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "OSError: dlopen(/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torchcodec/libtorchcodec_core6.dylib, 0x0006): Library not loaded: @rpath/libavutil.58.dylib\n",
      "  Referenced from: <A5B3FEB5-1F27-3A57-83D0-CBE4A25A52BA> /Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torchcodec/libtorchcodec_core6.dylib\n",
      "  Reason: tried: '/opt/homebrew/opt/ffmpeg/lib/libavutil.58.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/ffmpeg/lib/libavutil.58.dylib' (no such file), '/opt/homebrew/opt/ffmpeg/lib/libavutil.58.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/ffmpeg/lib/libavutil.58.dylib' (no such file), '/opt/homebrew/lib/libavutil.58.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libavutil.58.dylib' (no such file), '/opt/homebrew/lib/libavutil.58.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libavutil.58.dylib' (no such file)\n",
      "\n",
      "FFmpeg version 5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torchcodec/_core/ops.py\", line 57, in load_torchcodec_shared_libraries\n",
      "    torch.ops.load_library(core_library_path)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torch/_ops.py\", line 1478, in load_library\n",
      "    ctypes.CDLL(path)\n",
      "    ~~~~~~~~~~~^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ctypes/__init__.py\", line 390, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "                   ~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "OSError: dlopen(/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torchcodec/libtorchcodec_core5.dylib, 0x0006): Library not loaded: @rpath/libavutil.57.dylib\n",
      "  Referenced from: <2D6A73D8-E12F-372F-AE99-E1D9FB03230E> /Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torchcodec/libtorchcodec_core5.dylib\n",
      "  Reason: tried: '/opt/homebrew/opt/ffmpeg/lib/libavutil.57.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/ffmpeg/lib/libavutil.57.dylib' (no such file), '/opt/homebrew/opt/ffmpeg/lib/libavutil.57.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/ffmpeg/lib/libavutil.57.dylib' (no such file), '/opt/homebrew/lib/libavutil.57.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libavutil.57.dylib' (no such file), '/opt/homebrew/lib/libavutil.57.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libavutil.57.dylib' (no such file)\n",
      "\n",
      "FFmpeg version 4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torchcodec/_core/ops.py\", line 57, in load_torchcodec_shared_libraries\n",
      "    torch.ops.load_library(core_library_path)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torch/_ops.py\", line 1478, in load_library\n",
      "    ctypes.CDLL(path)\n",
      "    ~~~~~~~~~~~^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ctypes/__init__.py\", line 390, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "                   ~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "OSError: dlopen(/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torchcodec/libtorchcodec_core4.dylib, 0x0006): Library not loaded: @rpath/libavutil.56.dylib\n",
      "  Referenced from: <41A5A2EA-2967-3772-90F7-4FD6E5FCBA29> /Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/torchcodec/libtorchcodec_core4.dylib\n",
      "  Reason: tried: '/opt/homebrew/opt/ffmpeg/lib/libavutil.56.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/ffmpeg/lib/libavutil.56.dylib' (no such file), '/opt/homebrew/opt/ffmpeg/lib/libavutil.56.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/ffmpeg/lib/libavutil.56.dylib' (no such file), '/opt/homebrew/lib/libavutil.56.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libavutil.56.dylib' (no such file), '/opt/homebrew/lib/libavutil.56.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libavutil.56.dylib' (no such file)\n",
      "[end of libtorchcodec loading traceback].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n",
      "Settings loaded: <class 'app.core.config.Settings'>\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Test Setup\n",
    "\n",
    "Check if the test MP3 file exists and prepare test configuration"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T09:59:00.028257Z",
     "start_time": "2026-02-20T09:59:00.024795Z"
    }
   },
   "source": [
    "# Test file path\n",
    "test_audio_path = \"../data/test/Ïú†ÌÄ¥Ï¶à.mp3\"\n",
    "absolute_test_path = Path(test_audio_path).resolve()\n",
    "\n",
    "print(\"Test File Information:\")\n",
    "print(f\"  Path: {test_audio_path}\")\n",
    "print(f\"  Exists: {absolute_test_path.exists()}\")\n",
    "\n",
    "if absolute_test_path.exists():\n",
    "    file_size = absolute_test_path.stat().st_size\n",
    "    print(f\"  File size: {file_size:,} bytes ({file_size / (1024*1024):.2f} MB)\")\n",
    "    print(f\"  ‚úÖ Test file is ready\")\n",
    "else:\n",
    "    print(f\"  ‚ùå Test file not found!\")\n",
    "\n",
    "# Test configuration\n",
    "test_config = {\n",
    "    \"audio_file_path\": str(absolute_test_path),\n",
    "    \"user_id\": \"test_user\",\n",
    "    \"session_id\": \"test_session_001\"\n",
    "}\n",
    "\n",
    "print(f\"\\nTest Configuration:\")\n",
    "for key, value in test_config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test File Information:\n",
      "  Path: ../data/test/Ïú†ÌÄ¥Ï¶à.mp3\n",
      "  Exists: True\n",
      "  File size: 2,001,188 bytes (1.91 MB)\n",
      "  ‚úÖ Test file is ready\n",
      "\n",
      "Test Configuration:\n",
      "  audio_file_path: /Users/kimjunghyeon/Desktop/workspace/ai-agent/data/test/Ïú†ÌÄ¥Ï¶à.mp3\n",
      "  user_id: test_user\n",
      "  session_id: test_session_001\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Test Case 1: Individual Node Testing\n",
    "\n",
    "Test each node function individually to isolate any issues"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T10:08:46.770084Z",
     "start_time": "2026-02-20T09:59:01.049930Z"
    }
   },
   "source": [
    "async def test_transcribe_node():\n",
    "    \"\"\"Test the transcribe_audio node individually\"\"\"\n",
    "    print(\"=== Testing Transcribe Audio Node ===\")\n",
    "    \n",
    "    if not absolute_test_path.exists():\n",
    "        print(\"‚ùå Test file not found, skipping transcribe test\")\n",
    "        return None\n",
    "    \n",
    "    # Create mock state\n",
    "    state = {\n",
    "        \"audio_file_path\": str(absolute_test_path),\n",
    "        \"session_id\": \"test_session\",\n",
    "        \"user_id\": \"test_user\",\n",
    "        \"transcript\": [],\n",
    "        \"merged_transcript\": \"\",\n",
    "        \"minutes\": \"\"\n",
    "    }\n",
    "    \n",
    "    print(f\"Input state keys: {list(state.keys())}\")\n",
    "    print(f\"Audio file: {state['audio_file_path']}\")\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        print(\"Starting transcription...\")\n",
    "        \n",
    "        result = await transcribe_audio(state)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "        \n",
    "        print(f\"‚úÖ Transcription completed in {processing_time:.2f}s\")\n",
    "        print(f\"Result keys: {list(result.keys())}\")\n",
    "        \n",
    "        transcript = result.get(\"transcript\", [])\n",
    "        print(f\"Transcript segments: {len(transcript)}\")\n",
    "        \n",
    "        if transcript:\n",
    "            print(\"\\nFirst few segments:\")\n",
    "            for i, segment in enumerate(transcript):\n",
    "                start = segment.get(\"start\", 0)\n",
    "                end = segment.get(\"end\", 0)\n",
    "                text = segment.get(\"text\", \"\")\n",
    "                speaker = segment.get(\"speaker\", \"\")\n",
    "                print(f\"  {i+1}. [{start:.1f}s - {end:.1f}s] {speaker}: {text[:100]}{'...' if len(text) > 100 else ''}\")\n",
    "            \n",
    "            # Extract unique speakers\n",
    "            speakers = set(seg.get(\"speaker\", \"\") for seg in transcript)\n",
    "            print(f\"\\nUnique speakers detected: {sorted(speakers)}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No transcript segments returned\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Transcription failed: {str(e)}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        return None\n",
    "\n",
    "# Run transcribe test\n",
    "transcribe_result = await test_transcribe_node()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Transcribe Audio Node ===\n",
      "Input state keys: ['audio_file_path', 'session_id', 'user_id', 'transcript', 'merged_transcript', 'minutes']\n",
      "Audio file: /Users/kimjunghyeon/Desktop/workspace/ai-agent/data/test/Ïú†ÌÄ¥Ï¶à.mp3\n",
      "Starting transcription...\n",
      "2026-02-20 18:59:07 - whisperx.asr - INFO - No language specified, language will be detected for each audio file (increases inference time)\n",
      "2026-02-20 18:59:07 - whisperx.vads.pyannote - INFO - Performing voice activity detection using Pyannote...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.6.1. To apply the upgrade to your files permanently, run `python -m lightning.pytorch.utilities.upgrade_checkpoint ../.venv/lib/python3.13/site-packages/whisperx/assets/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-20 18:59:20 - whisperx.asr - INFO - Detected language: ko (1.00) in first 30s of audio\n",
      "2026-02-20 19:00:49 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-community-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/pyannote/audio/models/blocks/pooling.py:103: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Transcription completed in 227.86s\n",
      "Result keys: ['transcript']\n",
      "Transcript segments: 33\n",
      "\n",
      "First few segments:\n",
      "  1. [0.0s - 6.2s] SPEAKER_00: ÏïÑÎãà Í∑∏ Ï¢Ä Î≠ê Ïò§ÏÖ®ÏúºÎãàÍπå ÏñòÍ∏∞ Ïïà Ïó¨Ï≠§Î≥º ÏàòÍ∞Ä ÏóÜÎäîÎç∞ Ïò¨Ìï¥ Ï¢Ä Ïú†ÌÇ§Ï¶àÎäî Ï¢Ä Ïñ¥Îñ® Í≤É Í∞ôÏäµÎãàÍπå?\n",
      "  2. [6.3s - 7.9s] SPEAKER_01: Ïù¥Í≤å Ï¢Ä ÎäêÎÇå ÏûêÏ≤¥Î°ú.\n",
      "  3. [8.0s - 12.9s] SPEAKER_00: Ïñ¥ Ïôú Ï£ºÎ≥Ä Î∂ÑÎì§.\n",
      "\n",
      "Unique speakers detected: ['SPEAKER_00', 'SPEAKER_01']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "cell-7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T10:04:12.282036Z",
     "start_time": "2026-02-20T10:04:12.276256Z"
    }
   },
   "source": [
    "async def test_merge_node(transcript_data):\n",
    "    \"\"\"Test the merge_transcript node\"\"\"\n",
    "    print(\"\\n=== Testing Merge Transcript Node ===\")\n",
    "    \n",
    "    if not transcript_data or not transcript_data.get(\"transcript\"):\n",
    "        print(\"‚ùå No transcript data available, skipping merge test\")\n",
    "        return None\n",
    "    \n",
    "    # Create state with transcript data\n",
    "    state = {\n",
    "        \"audio_file_path\": str(absolute_test_path),\n",
    "        \"session_id\": \"test_session\",\n",
    "        \"user_id\": \"test_user\",\n",
    "        \"transcript\": transcript_data[\"transcript\"],\n",
    "        \"merged_transcript\": \"\",\n",
    "        \"minutes\": \"\"\n",
    "    }\n",
    "    \n",
    "    print(f\"Input segments: {len(state['transcript'])}\")\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        result = await merge_transcript(state)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"‚úÖ Merge completed in {end_time - start_time:.2f}s\")\n",
    "        \n",
    "        merged_text = result.get(\"merged_transcript\", \"\")\n",
    "        print(f\"Merged transcript length: {len(merged_text)} chars\")\n",
    "        \n",
    "        if merged_text:\n",
    "            print(\"\\nMerged transcript preview:\")\n",
    "            print(\"-\" * 50)\n",
    "            print(merged_text[:500] + (\"...\" if len(merged_text) > 500 else \"\"))\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Count speaker lines\n",
    "            lines = merged_text.split('\\n')\n",
    "            speaker_lines = [line for line in lines if ':' in line and line.strip()]\n",
    "            print(f\"\\nSpeaker lines: {len(speaker_lines)}\")\n",
    "            \n",
    "            # Show first few speaker lines\n",
    "            if speaker_lines:\n",
    "                print(\"First few speaker lines:\")\n",
    "                for i, line in enumerate(speaker_lines[:5]):\n",
    "                    print(f\"  {i+1}. {line[:100]}{'...' if len(line) > 100 else ''}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No merged transcript returned\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Merge failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Run merge test if transcription succeeded\n",
    "merge_result = await test_merge_node(transcribe_result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Merge Transcript Node ===\n",
      "Input segments: 33\n",
      "‚úÖ Merge completed in 0.00s\n",
      "Merged transcript length: 954 chars\n",
      "\n",
      "Merged transcript preview:\n",
      "--------------------------------------------------\n",
      "Speaker 1: ÏïÑÎãà Í∑∏ Ï¢Ä Î≠ê Ïò§ÏÖ®ÏúºÎãàÍπå ÏñòÍ∏∞ Ïïà Ïó¨Ï≠§Î≥º ÏàòÍ∞Ä ÏóÜÎäîÎç∞ Ïò¨Ìï¥ Ï¢Ä Ïú†ÌÇ§Ï¶àÎäî Ï¢Ä Ïñ¥Îñ® Í≤É Í∞ôÏäµÎãàÍπå?\n",
      "Speaker 2: Ïù¥Í≤å Ï¢Ä ÎäêÎÇå ÏûêÏ≤¥Î°ú.\n",
      "Speaker 1: Ïñ¥ Ïôú Ï£ºÎ≥Ä Î∂ÑÎì§.\n",
      "Speaker 2: ÏùºÎã®ÏùÄ Ïó∞Ïï†Ïùò Ïù∏Ïó∞Ïù¥ ÏßßÍ±∞ÎÇò ÏóÜÍ≥† ÏùºÎ≥µÏù¥ ÌÑ∞ÏßÑ ÏÉÅÎì§Ïù¥ ÎßéÏúºÎãàÍπå.\n",
      "Speaker 1: ÏñòÍ∏∞Í∞Ä Ï∂©Í≤©Ï†ÅÏù¥ÎÑ§. Ïó∞Ïï† Ïö¥Ïù¥ ÏóÜÍ≥† ÏùºÎ≥µÏù¥ ÌÑ∞ÏßÑ Î∂ÑÎì§Ïù¥ Ïó¨Í∏∞ ÎßéÏïÑÏöî?\n",
      "Speaker 2: Îî¥Ïßì Ïïà ÌïòÍ≥†. Îî¥Ïßì Î™ª ÌïòÍ≥† ÏùºÎßå Ìï† Í±∞ÎãàÍπå. Ïïà ÌïòÎäî Í≤å ÏïÑÎãàÎùº Îî¥ÏßìÏùÑ Î™ª ÌïòÍ≥†? Ïú†Ïû¨ÏÑùÎãòÏóêÍ≤åÎäî Ïù¥Î≥¥Îã§ Îçî Îì†Îì†Ìï† Ïàò ÏóÜÎã§.\n",
      "Speaker 1: Í≥†ÎßôÏäµÎãàÎã§. Îòê Ïó¨Îü¨Î∂Ñ ÎçïÎ∂ÑÏóê Ïù¥Î†áÍ≤å 1ÎÖÑ... Ï†ÄÎèÑ Ï¢Ä Ïñ¥Îîî Í∞ÄÎ©¥ ÏùºÎ≥µÏù¥ ÌÉÄÍ≥†ÎÇ¨Îã§ Ïù¥Îü∞ ÏñòÍ∏∞Î•º Ï¢Ä Îì£Í∏∞ÎèÑ ÌïòÎäîÎç∞ Ï†ÄÎèÑ Ï¢Ä Í∑∏ÎûòÏöî. Í∑∏Î†áÏ£†.\n",
      "Speaker 2: Í∏∞ÏÑ∏ ÏûàÍ≤å Ïò¨ÎùºÏò§Îäî Î¨ºÏùò ÌùêÎ¶ÑÏóê ÌÉîÎã§ Ïù¥Î†áÍ≤å Î≥º Ïàò ÏûàÎäî Í±∞Ï£†. Í∑∏Îü¨ÎãàÍπå Í∏∞ÏÑ∏ ÏûàÍ≤å Ïò¨ÎùºÏò§Îäî Î™ÖÎ¶¨Ïùò ÎåÄÏò®Í≥º ÏÑ∏Ïò®ÏùÑ ÌÉÄÏÑú ÏñºÍµ¥ÏùÑ Ïù¥Í≤®ÎÉàÎã§.\n",
      "Speaker 1: ÏïÑÏù¥ ÎÇò Ï†ïÎßê ÏßÑÏßú... ÏïÑÎãà... ...\n",
      "--------------------------------------------------\n",
      "\n",
      "Speaker lines: 10\n",
      "First few speaker lines:\n",
      "  1. Speaker 1: ÏïÑÎãà Í∑∏ Ï¢Ä Î≠ê Ïò§ÏÖ®ÏúºÎãàÍπå ÏñòÍ∏∞ Ïïà Ïó¨Ï≠§Î≥º ÏàòÍ∞Ä ÏóÜÎäîÎç∞ Ïò¨Ìï¥ Ï¢Ä Ïú†ÌÇ§Ï¶àÎäî Ï¢Ä Ïñ¥Îñ® Í≤É Í∞ôÏäµÎãàÍπå?\n",
      "  2. Speaker 2: Ïù¥Í≤å Ï¢Ä ÎäêÎÇå ÏûêÏ≤¥Î°ú.\n",
      "  3. Speaker 1: Ïñ¥ Ïôú Ï£ºÎ≥Ä Î∂ÑÎì§.\n",
      "  4. Speaker 2: ÏùºÎã®ÏùÄ Ïó∞Ïï†Ïùò Ïù∏Ïó∞Ïù¥ ÏßßÍ±∞ÎÇò ÏóÜÍ≥† ÏùºÎ≥µÏù¥ ÌÑ∞ÏßÑ ÏÉÅÎì§Ïù¥ ÎßéÏúºÎãàÍπå.\n",
      "  5. Speaker 1: ÏñòÍ∏∞Í∞Ä Ï∂©Í≤©Ï†ÅÏù¥ÎÑ§. Ïó∞Ïï† Ïö¥Ïù¥ ÏóÜÍ≥† ÏùºÎ≥µÏù¥ ÌÑ∞ÏßÑ Î∂ÑÎì§Ïù¥ Ïó¨Í∏∞ ÎßéÏïÑÏöî?\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "cell-8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T10:05:12.278510Z",
     "start_time": "2026-02-20T10:04:57.798477Z"
    }
   },
   "source": [
    "async def test_generate_minutes_node(merged_data):\n",
    "    \"\"\"Test the generate_minutes node\"\"\"\n",
    "    print(\"\\n=== Testing Generate Minutes Node ===\")\n",
    "    \n",
    "    if not merged_data or not merged_data.get(\"merged_transcript\"):\n",
    "        print(\"‚ùå No merged transcript available, skipping minutes generation test\")\n",
    "        return None\n",
    "    \n",
    "    # Create state with merged transcript\n",
    "    state = {\n",
    "        \"audio_file_path\": str(absolute_test_path),\n",
    "        \"session_id\": \"test_session\",\n",
    "        \"user_id\": \"test_user\",\n",
    "        \"transcript\": transcribe_result.get(\"transcript\", []) if transcribe_result else [],\n",
    "        \"merged_transcript\": merged_data[\"merged_transcript\"],\n",
    "        \"minutes\": \"\"\n",
    "    }\n",
    "    \n",
    "    print(f\"Input merged transcript length: {len(state['merged_transcript'])} chars\")\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        print(\"Starting minutes generation with LLM...\")\n",
    "        \n",
    "        result = await generate_minutes(state)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"‚úÖ Minutes generation completed in {end_time - start_time:.2f}s\")\n",
    "        \n",
    "        minutes = result.get(\"minutes\", \"\")\n",
    "        print(f\"Generated minutes length: {len(minutes)} chars\")\n",
    "        \n",
    "        if minutes and len(minutes) > 50:\n",
    "            print(\"\\nGenerated Meeting Minutes:\")\n",
    "            print(\"=\" * 60)\n",
    "            print(minutes[:1000] + (\"\\n\\n[... truncated for display ...]\" if len(minutes) > 1000 else \"\"))\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            # Analyze the structure\n",
    "            lines = minutes.split('\\n')\n",
    "            headers = [line for line in lines if line.startswith('#')]\n",
    "            print(f\"\\nStructure analysis:\")\n",
    "            print(f\"  Total lines: {len(lines)}\")\n",
    "            print(f\"  Header lines: {len(headers)}\")\n",
    "            print(f\"  Headers found: {headers[:5] if headers else 'None'}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Minutes generation may have failed or returned insufficient content\")\n",
    "            if minutes:\n",
    "                print(f\"Content: {minutes}\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Minutes generation failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Run minutes generation test if merge succeeded\n",
    "minutes_result = await test_generate_minutes_node(merge_result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Generate Minutes Node ===\n",
      "Input merged transcript length: 954 chars\n",
      "Starting minutes generation with LLM...\n",
      "‚úÖ Minutes generation completed in 14.47s\n",
      "Generated minutes length: 716 chars\n",
      "\n",
      "Generated Meeting Minutes:\n",
      "============================================================\n",
      "# ÌöåÏùòÎ°ù\n",
      "\n",
      "## ÌöåÏùò Í∞úÏöî\n",
      "- ÏùºÏãú: 2023ÎÖÑ 10Ïõî 10Ïùº\n",
      "- Ï∞∏ÏÑùÏûê: 2Î™Ö (Speaker 1, Speaker 2)\n",
      "- ÌöåÏùò Ï£ºÏ†ú: Ïú†ÌÇ§Ï¶à ÌîÑÎ°úÍ∑∏Îû®Ïùò Ï†ÑÎßù Î∞è Í¥ÄÏÉÅÍ≥º Ïö¥Ïóê ÎåÄÌïú ÎÖºÏùò\n",
      "\n",
      "## Ï£ºÏöî ÎÖºÏùò ÏÇ¨Ìï≠\n",
      "### 1. Ïú†ÌÇ§Ï¶à ÌîÑÎ°úÍ∑∏Îû®Ïùò Ï†ÑÎßù\n",
      "- Speaker 1ÏùÄ Ïú†ÌÇ§Ï¶à ÌîÑÎ°úÍ∑∏Îû®Ïùò Ìñ•ÌõÑ Ï†ÑÎßùÏóê ÎåÄÌï¥ ÏßàÎ¨∏Ìï®.\n",
      "- Speaker 2Îäî Ïó∞Ïï† Ïö¥Ïù¥ Î∂ÄÏ°±ÌïòÍ≥† ÏùºÎ≥µÏù¥ ÎßéÏùÄ ÏÇ¨ÎûåÎì§Ïù¥ ÎßéÎã§Í≥† Ïñ∏Í∏âÌïòÎ©∞, Ïù¥Îäî Ïú†ÌÇ§Ï¶à ÌîÑÎ°úÍ∑∏Îû®Ïóê Í∏çÏ†ïÏ†ÅÏù∏ ÏòÅÌñ•ÏùÑ ÎØ∏Ïπ† Í≤ÉÏù¥ÎùºÍ≥† ÏÑ§Î™Ö.\n",
      "\n",
      "### 2. Í¥ÄÏÉÅÍ≥º Ïö¥Ïùò Í¥ÄÍ≥Ñ\n",
      "- ÏûòÏÉùÍ∏¥ Ïô∏Î™®Í∞Ä Î∞òÎìúÏãú Ï¢ãÏùÄ Í¥ÄÏÉÅÏùÑ ÏùòÎØ∏ÌïòÏßÄÎäî ÏïäÎäîÎã§Îäî Speaker 2Ïùò ÏÑ§Î™Ö.\n",
      "- ÏñºÍµ¥Ïùò ÏÉùÍπÄÏÉàÏôÄ Ïö¥Ïùò Í¥ÄÍ≥ÑÏóê ÎåÄÌïú ÏÑ§Î™Ö: ÏñºÍµ¥ÎøêÎßå ÏïÑÎãàÎùº ÏÇ¨Ï£º, ÌíçÏàò, Í∂ÅÌï© Îì± Îã§ÏñëÌïú ÏöîÏÜåÍ∞Ä Ïö¥Ïóê ÏòÅÌñ•ÏùÑ ÎØ∏Ïπ®.\n",
      "\n",
      "## Í≤∞Ï†ï ÏÇ¨Ìï≠\n",
      "1. Ïú†ÌÇ§Ï¶à ÌîÑÎ°úÍ∑∏Îû®ÏùÄ ÏùºÎ≥µÏù¥ ÎßéÏùÄ ÏÇ¨ÎûåÎì§Î°ú Ïù∏Ìï¥ Í∏çÏ†ïÏ†ÅÏù∏ Î∞©Ìñ•ÏúºÎ°ú ÎÇòÏïÑÍ∞à Í≤ÉÏúºÎ°ú ÏòàÏÉÅÎê®.\n",
      "2. Ïô∏Î™®ÏôÄ Í¥ÄÏÉÅÏùò Í¥ÄÍ≥ÑÎäî Îã®ÏàúÌïòÏßÄ ÏïäÏúºÎ©∞, Îã§ÏñëÌïú ÏöîÏÜåÍ∞Ä Ïö¥Ïóê ÏòÅÌñ•ÏùÑ ÎØ∏ÏπúÎã§Îäî Ï†êÏùÑ Ïù∏Ïãù.\n",
      "\n",
      "## Ïï°ÏÖò ÏïÑÏù¥ÌÖú\n",
      "1. [Speaker 1] - Ïú†ÌÇ§Ï¶à ÌîÑÎ°úÍ∑∏Îû®Ïùò Ìñ•ÌõÑ Í≥ÑÌöçÏóê ÎåÄÌïú Íµ¨Ï≤¥Ï†ÅÏù∏ Ï†ÑÎûµ ÏàòÎ¶Ω - [2023ÎÖÑ 11Ïõî 1Ïùº]\n",
      "2. [Speaker 2] - Í¥ÄÏÉÅÍ≥º Ïö¥Ïóê ÎåÄÌïú Ï∂îÍ∞Ä Ïó∞Íµ¨ Î∞è ÏûêÎ£å Ï†úÍ≥µ - [2023ÎÖÑ 11Ïõî 15Ïùº]\n",
      "\n",
      "## Í∏∞ÌÉÄ ÏÇ¨Ìï≠\n",
      "- Ï∂îÍ∞Ä ÎÖºÏùòÍ∞Ä ÌïÑÏöîÌïú ÏÇ¨Ìï≠: Í¥ÄÏÉÅÍ≥º Ïö¥Ïùò Í¥ÄÍ≥ÑÏóê ÎåÄÌïú Ïã¨Ï∏µ Î∂ÑÏÑù ÌïÑÏöî.\n",
      "- Îã§Ïùå ÌöåÏùò ÏùºÏ†ï: 2023ÎÖÑ 11Ïõî 20Ïùº ÏòàÏ†ï.\n",
      "============================================================\n",
      "\n",
      "Structure analysis:\n",
      "  Total lines: 27\n",
      "  Header lines: 8\n",
      "  Headers found: ['# ÌöåÏùòÎ°ù', '## ÌöåÏùò Í∞úÏöî', '## Ï£ºÏöî ÎÖºÏùò ÏÇ¨Ìï≠', '### 1. Ïú†ÌÇ§Ï¶à ÌîÑÎ°úÍ∑∏Îû®Ïùò Ï†ÑÎßù', '### 2. Í¥ÄÏÉÅÍ≥º Ïö¥Ïùò Í¥ÄÍ≥Ñ']\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Test Case 2: Complete Workflow Testing\n",
    "\n",
    "Test the complete meeting workflow end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-10",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-02-20T10:05:36.588422Z"
    }
   },
   "source": [
    "async def test_complete_workflow():\n",
    "    \"\"\"Test the complete meeting workflow\"\"\"\n",
    "    print(\"\\n=== Complete Workflow Test ===\")\n",
    "    \n",
    "    if not absolute_test_path.exists():\n",
    "        print(\"‚ùå Test file not found, skipping workflow test\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Testing complete meeting processing workflow...\")\n",
    "    print(f\"Audio file: {absolute_test_path}\")\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        result = await process_meeting(\n",
    "            audio_file_path=str(absolute_test_path),\n",
    "            user_id=\"workflow_test_user\",\n",
    "            session_id=\"workflow_test_session\"\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        \n",
    "        print(f\"\\n‚úÖ Complete workflow finished in {total_time:.2f}s ({total_time/60:.1f} minutes)\")\n",
    "        print(f\"Result keys: {list(result.keys())}\")\n",
    "        \n",
    "        # Analyze results\n",
    "        transcript = result.get(\"transcript\", [])\n",
    "        merged_transcript = result.get(\"merged_transcript\", \"\")\n",
    "        minutes = result.get(\"minutes\", \"\")\n",
    "        session_id = result.get(\"session_id\", \"\")\n",
    "        \n",
    "        print(f\"\\nWorkflow Results Summary:\")\n",
    "        print(f\"  Session ID: {session_id}\")\n",
    "        print(f\"  Transcript segments: {len(transcript)}\")\n",
    "        print(f\"  Merged transcript: {len(merged_transcript)} chars\")\n",
    "        print(f\"  Meeting minutes: {len(minutes)} chars\")\n",
    "        \n",
    "        # Show final results\n",
    "        if minutes and len(minutes) > 100:\n",
    "            print(f\"\\nüìù Final Meeting Minutes:\")\n",
    "            print(\"=\" * 80)\n",
    "            print(minutes)\n",
    "            print(\"=\" * 80)\n",
    "            print(f\"‚úÖ Workflow completed successfully!\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Minutes may be incomplete or missing\")\n",
    "            if minutes:\n",
    "                print(f\"Minutes content: {minutes}\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Complete workflow failed: {str(e)}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        import traceback\n",
    "        print(f\"Traceback: {traceback.format_exc()}\")\n",
    "        return None\n",
    "\n",
    "# Run complete workflow test\n",
    "workflow_result = await test_complete_workflow()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Complete Workflow Test ===\n",
      "Testing complete meeting processing workflow...\n",
      "Audio file: /Users/kimjunghyeon/Desktop/workspace/ai-agent/data/test/Ïú†ÌÄ¥Ï¶à.mp3\n",
      "2026-02-20 19:05:51 - whisperx.asr - INFO - Detected language: ko (1.00) in first 30s of audio\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Test Case 3: Streaming Workflow Testing\n",
    "\n",
    "Test the streaming version of the meeting workflow"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "async def test_streaming_workflow():\n",
    "    \"\"\"Test the streaming meeting workflow\"\"\"\n",
    "    print(\"\\n=== Streaming Workflow Test ===\")\n",
    "    \n",
    "    if not absolute_test_path.exists():\n",
    "        print(\"‚ùå Test file not found, skipping streaming test\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Testing streaming meeting processing workflow...\")\n",
    "    print(f\"Audio file: {absolute_test_path}\")\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        events_received = 0\n",
    "        final_result = None\n",
    "        \n",
    "        async for event in process_meeting_stream(\n",
    "            audio_file_path=str(absolute_test_path),\n",
    "            user_id=\"streaming_test_user\",\n",
    "            session_id=\"streaming_test_session\"\n",
    "        ):\n",
    "            events_received += 1\n",
    "            event_type = event.get(\"type\", \"\")\n",
    "            message = event.get(\"message\", \"\")\n",
    "            step = event.get(\"step\", \"\")\n",
    "            \n",
    "            print(f\"  Event {events_received}: {event_type} - {step} - {message}\")\n",
    "            \n",
    "            # Check for completion\n",
    "            if event_type == \"complete\":\n",
    "                final_result = event\n",
    "                print(f\"    üìÑ Final minutes length: {len(event.get('minutes', ''))} chars\")\n",
    "            elif event_type == \"error\":\n",
    "                print(f\"    ‚ùå Error: {event.get('error', '')}\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        \n",
    "        print(f\"\\n‚úÖ Streaming workflow completed in {total_time:.2f}s\")\n",
    "        print(f\"Total events received: {events_received}\")\n",
    "        \n",
    "        if final_result:\n",
    "            minutes = final_result.get(\"minutes\", \"\")\n",
    "            if minutes:\n",
    "                print(f\"\\nüìù Final Streaming Result:\")\n",
    "                print(\"-\" * 80)\n",
    "                print(minutes[:800] + (\"\\n\\n[... truncated for display ...]\" if len(minutes) > 800 else \"\"))\n",
    "                print(\"-\" * 80)\n",
    "                return final_result\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No final result received\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Streaming workflow failed: {str(e)}\")\n",
    "        import traceback\n",
    "        print(f\"Traceback: {traceback.format_exc()}\")\n",
    "        return None\n",
    "\n",
    "# Run streaming workflow test\n",
    "streaming_result = await test_streaming_workflow()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Test Case 4: Error Handling and Edge Cases\n",
    "\n",
    "Test various error scenarios and edge cases"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "async def test_error_handling():\n",
    "    \"\"\"Test error handling and edge cases\"\"\"\n",
    "    print(\"\\n=== Error Handling Tests ===\")\n",
    "    \n",
    "    test_cases = [\n",
    "        {\n",
    "            \"name\": \"Non-existent file\",\n",
    "            \"audio_path\": \"data/test/nonexistent.mp3\",\n",
    "            \"expect_error\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Empty file path\",\n",
    "            \"audio_path\": \"\",\n",
    "            \"expect_error\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Invalid file path\",\n",
    "            \"audio_path\": \"/invalid/path/to/file.mp3\",\n",
    "            \"expect_error\": True\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, case in enumerate(test_cases, 1):\n",
    "        print(f\"\\nTest {i}: {case['name']}\")\n",
    "        print(f\"  Path: {case['audio_path']}\")\n",
    "        print(f\"  Expect error: {case['expect_error']}\")\n",
    "        \n",
    "        try:\n",
    "            result = await process_meeting(\n",
    "                audio_file_path=case['audio_path'],\n",
    "                user_id=\"error_test_user\",\n",
    "                session_id=f\"error_test_{i}\"\n",
    "            )\n",
    "            \n",
    "            minutes = result.get(\"minutes\", \"\")\n",
    "            \n",
    "            if case['expect_error']:\n",
    "                if \"Ïò§Î•ò\" in minutes or \"Error\" in minutes or len(minutes) < 50:\n",
    "                    print(f\"  ‚úÖ Error handled correctly: {minutes[:100]}{'...' if len(minutes) > 100 else ''}\")\n",
    "                else:\n",
    "                    print(f\"  ‚ö†Ô∏è Expected error but got result: {minutes[:100]}\")\n",
    "            else:\n",
    "                print(f\"  ‚úÖ Successful result: {len(minutes)} chars\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            if case['expect_error']:\n",
    "                print(f\"  ‚úÖ Exception handled as expected: {str(e)[:100]}\")\n",
    "            else:\n",
    "                print(f\"  ‚ùå Unexpected exception: {str(e)[:100]}\")\n",
    "\n",
    "await test_error_handling()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Test Case 5: Performance Analysis\n",
    "\n",
    "Analyze performance characteristics of the meeting workflow"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "async def analyze_performance():\n",
    "    \"\"\"Analyze workflow performance\"\"\"\n",
    "    print(\"\\n=== Performance Analysis ===\")\n",
    "    \n",
    "    if not absolute_test_path.exists():\n",
    "        print(\"‚ùå Test file not found, skipping performance analysis\")\n",
    "        return\n",
    "    \n",
    "    file_size = absolute_test_path.stat().st_size\n",
    "    print(f\"Audio file size: {file_size:,} bytes ({file_size / (1024*1024):.2f} MB)\")\n",
    "    \n",
    "    # Estimate audio duration (rough estimate: ~1MB per minute for MP3)\n",
    "    estimated_duration = file_size / (1024*1024)  # rough minutes estimate\n",
    "    print(f\"Estimated audio duration: ~{estimated_duration:.1f} minutes\")\n",
    "    \n",
    "    performance_data = []\n",
    "    \n",
    "    # Single run with timing for each phase\n",
    "    print(\"\\nRunning performance test...\")\n",
    "    \n",
    "    try:\n",
    "        total_start = time.time()\n",
    "        \n",
    "        # Test individual nodes with timing\n",
    "        state = {\n",
    "            \"audio_file_path\": str(absolute_test_path),\n",
    "            \"session_id\": \"perf_test\",\n",
    "            \"user_id\": \"perf_user\",\n",
    "            \"transcript\": [],\n",
    "            \"merged_transcript\": \"\",\n",
    "            \"minutes\": \"\"\n",
    "        }\n",
    "        \n",
    "        # Phase 1: Transcription\n",
    "        phase_start = time.time()\n",
    "        transcribe_result = await transcribe_audio(state)\n",
    "        transcribe_time = time.time() - phase_start\n",
    "        \n",
    "        # Phase 2: Merging\n",
    "        if transcribe_result and transcribe_result.get(\"transcript\"):\n",
    "            state[\"transcript\"] = transcribe_result[\"transcript\"]\n",
    "            phase_start = time.time()\n",
    "            merge_result = await merge_transcript(state)\n",
    "            merge_time = time.time() - phase_start\n",
    "            \n",
    "            # Phase 3: Minutes generation\n",
    "            if merge_result and merge_result.get(\"merged_transcript\"):\n",
    "                state[\"merged_transcript\"] = merge_result[\"merged_transcript\"]\n",
    "                phase_start = time.time()\n",
    "                minutes_result = await generate_minutes(state)\n",
    "                minutes_time = time.time() - phase_start\n",
    "            else:\n",
    "                merge_time = 0\n",
    "                minutes_time = 0\n",
    "        else:\n",
    "            transcribe_time = 0\n",
    "            merge_time = 0\n",
    "            minutes_time = 0\n",
    "        \n",
    "        total_time = time.time() - total_start\n",
    "        \n",
    "        print(f\"\\nPerformance Results:\")\n",
    "        print(f\"  Transcription time: {transcribe_time:.2f}s ({transcribe_time/total_time*100:.1f}%)\")\n",
    "        print(f\"  Merge time: {merge_time:.2f}s ({merge_time/total_time*100:.1f}%)\")\n",
    "        print(f\"  Minutes generation time: {minutes_time:.2f}s ({minutes_time/total_time*100:.1f}%)\")\n",
    "        print(f\"  Total time: {total_time:.2f}s ({total_time/60:.1f} minutes)\")\n",
    "        \n",
    "        # Performance metrics\n",
    "        if estimated_duration > 0:\n",
    "            processing_ratio = total_time / (estimated_duration * 60)  # total_time in seconds, duration in minutes\n",
    "            print(f\"  Processing ratio: {processing_ratio:.2f}x (higher is slower)\")\n",
    "            \n",
    "            if processing_ratio < 0.5:\n",
    "                print(f\"  üöÄ Excellent performance (< 0.5x real-time)\")\n",
    "            elif processing_ratio < 1.0:\n",
    "                print(f\"  ‚úÖ Good performance (< 1x real-time)\")\n",
    "            elif processing_ratio < 2.0:\n",
    "                print(f\"  ‚ö†Ô∏è Acceptable performance (< 2x real-time)\")\n",
    "            else:\n",
    "                print(f\"  ‚ùå Slow performance (> 2x real-time)\")\n",
    "        \n",
    "        # Memory and resource analysis would go here if needed\n",
    "        print(f\"\\nResource Usage Notes:\")\n",
    "        print(f\"  - WhisperX models are loaded and cached\")\n",
    "        print(f\"  - GPU usage: {'Yes' if settings.WHISPERX_DEVICE == 'cuda' else 'No (CPU only)'}\")\n",
    "        print(f\"  - Model size: {settings.WHISPERX_MODEL}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Performance test failed: {str(e)}\")\n",
    "\n",
    "await analyze_performance()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Test Case 6: Manual Testing and Configuration\n",
    "\n",
    "Custom tests and configuration validation"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "def validate_configuration():\n",
    "    \"\"\"Validate the configuration for meeting workflow\"\"\"\n",
    "    print(\"=== Configuration Validation ===\")\n",
    "    \n",
    "    # Check required settings\n",
    "    config_checks = [\n",
    "        (\"OPENAI_API_KEY\", settings.OPENAI_API_KEY, \"OpenAI API access\"),\n",
    "        (\"HF_TOKEN\", getattr(settings, 'HF_TOKEN', ''), \"HuggingFace token for speaker diarization\"),\n",
    "        (\"WHISPERX_MODEL\", settings.WHISPERX_MODEL, \"WhisperX model size\"),\n",
    "        (\"WHISPERX_DEVICE\", settings.WHISPERX_DEVICE, \"Processing device\"),\n",
    "        (\"WHISPERX_LANGUAGE\", settings.WHISPERX_LANGUAGE, \"Default language\"),\n",
    "        (\"MINUTES_MODEL\", settings.MINUTES_MODEL, \"Meeting minutes LLM model\"),\n",
    "        (\"MINUTES_TEMPERATURE\", str(settings.MINUTES_TEMPERATURE), \"LLM temperature\")\n",
    "    ]\n",
    "    \n",
    "    print(\"Configuration Status:\")\n",
    "    all_good = True\n",
    "    \n",
    "    for key, value, description in config_checks:\n",
    "        if value and str(value).strip():\n",
    "            status = \"‚úÖ\"\n",
    "            display_value = value if key not in ['OPENAI_API_KEY', 'HF_TOKEN'] else \"***[SET]***\"\n",
    "        else:\n",
    "            status = \"‚ùå\"\n",
    "            display_value = \"[NOT SET]\"\n",
    "            all_good = False\n",
    "        \n",
    "        print(f\"  {status} {key}: {display_value} ({description})\")\n",
    "    \n",
    "    print(f\"\\nOverall configuration: {'‚úÖ Ready' if all_good else '‚ùå Issues found'}\")\n",
    "    \n",
    "    # Check system requirements\n",
    "    print(\"\\nSystem Requirements:\")\n",
    "    \n",
    "    try:\n",
    "        import torch\n",
    "        print(f\"  ‚úÖ PyTorch: {torch.__version__}\")\n",
    "        print(f\"  ‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"      GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    except ImportError:\n",
    "        print(f\"  ‚ùå PyTorch not installed\")\n",
    "    \n",
    "    try:\n",
    "        import whisperx\n",
    "        print(f\"  ‚úÖ WhisperX available\")\n",
    "    except ImportError:\n",
    "        print(f\"  ‚ùå WhisperX not installed\")\n",
    "    \n",
    "    return all_good\n",
    "\n",
    "config_valid = validate_configuration()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "async def test_custom_audio(audio_path: str = None):\n",
    "    \"\"\"\n",
    "    Test with a custom audio file path\n",
    "    \"\"\"\n",
    "    if not audio_path:\n",
    "        audio_path = str(absolute_test_path)\n",
    "    \n",
    "    print(f\"=== Custom Audio Test ===\")\n",
    "    print(f\"Testing with: {audio_path}\")\n",
    "    \n",
    "    if not Path(audio_path).exists():\n",
    "        print(f\"‚ùå File not found: {audio_path}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        result = await process_meeting(\n",
    "            audio_file_path=audio_path,\n",
    "            user_id=\"custom_test_user\",\n",
    "            session_id=\"custom_test_session\"\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Processing completed\")\n",
    "        print(f\"Minutes length: {len(result.get('minutes', ''))} chars\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Custom test failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Run with the default test file\n",
    "# custom_result = await test_custom_audio()\n",
    "print(\"Custom audio test function ready. Use: await test_custom_audio('path/to/your/audio.mp3')\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Test Summary and Results\n",
    "\n",
    "Overall test summary and recommendations"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MEETING WORKFLOW TEST SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Collect test results\n",
    "test_results = {\n",
    "    \"Configuration\": config_valid,\n",
    "    \"Test File Available\": absolute_test_path.exists(),\n",
    "    \"Individual Node Tests\": {\n",
    "        \"Transcription\": transcribe_result is not None,\n",
    "        \"Merge Transcript\": merge_result is not None,\n",
    "        \"Generate Minutes\": minutes_result is not None\n",
    "    },\n",
    "    \"Workflow Tests\": {\n",
    "        \"Complete Workflow\": workflow_result is not None,\n",
    "        \"Streaming Workflow\": streaming_result is not None\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "print(f\"  üìÅ Test file available: {'‚úÖ' if test_results['Test File Available'] else '‚ùå'}\")\n",
    "print(f\"  ‚öôÔ∏è  Configuration valid: {'‚úÖ' if test_results['Configuration'] else '‚ùå'}\")\n",
    "\n",
    "print(f\"\\n  Individual Nodes:\")\n",
    "for node, success in test_results['Individual Node Tests'].items():\n",
    "    print(f\"    {node}: {'‚úÖ' if success else '‚ùå'}\")\n",
    "\n",
    "print(f\"\\n  Workflow Tests:\")\n",
    "for workflow, success in test_results['Workflow Tests'].items():\n",
    "    print(f\"    {workflow}: {'‚úÖ' if success else '‚ùå'}\")\n",
    "\n",
    "# Overall assessment\n",
    "all_tests_passed = (\n",
    "    test_results['Configuration'] and \n",
    "    test_results['Test File Available'] and\n",
    "    all(test_results['Individual Node Tests'].values()) and\n",
    "    all(test_results['Workflow Tests'].values())\n",
    ")\n",
    "\n",
    "print(f\"\\nüéØ Overall Status: {'‚úÖ ALL TESTS PASSED' if all_tests_passed else '‚ö†Ô∏è  Some tests failed or skipped'}\")\n",
    "\n",
    "print(f\"\\nKey Features Tested:\")\n",
    "print(f\"  üé§ WhisperX-based speech-to-text transcription\")\n",
    "print(f\"  üë• Speaker diarization and identification\")\n",
    "print(f\"  üìù Automatic transcript merging and formatting\")\n",
    "print(f\"  ü§ñ LLM-powered meeting minutes generation\")\n",
    "print(f\"  üîÑ Complete workflow orchestration\")\n",
    "print(f\"  üì° Real-time streaming processing\")\n",
    "print(f\"  ‚ö†Ô∏è  Error handling and edge cases\")\n",
    "\n",
    "print(f\"\\nAPI Endpoints Available:\")\n",
    "print(f\"  POST /meeting/upload - Upload audio and get meeting minutes\")\n",
    "print(f\"  POST /meeting/upload/stream - Upload audio with streaming processing\")\n",
    "\n",
    "print(f\"\\nRecommendations:\")\n",
    "if not config_valid:\n",
    "    print(f\"  ‚ö†Ô∏è  Fix configuration issues (especially HF_TOKEN for speaker diarization)\")\n",
    "if not test_results['Test File Available']:\n",
    "    print(f\"  üìÅ Add test audio files to data/test/ directory\")\n",
    "print(f\"  üöÄ Consider GPU acceleration by setting WHISPERX_DEVICE=cuda\")\n",
    "print(f\"  üìä Monitor performance with different audio lengths and quality\")\n",
    "print(f\"  üîí Implement proper file validation and security measures for production\")\n",
    "print(f\"  üíæ Consider adding database storage for meeting records if needed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Quick Test Functions\n",
    "\n",
    "Convenient functions for quick testing during development"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "# Quick test functions for development\n",
    "\n",
    "async def quick_test():\n",
    "    \"\"\"Quick test with the default file\"\"\"\n",
    "    if not absolute_test_path.exists():\n",
    "        print(\"‚ùå Test file not available\")\n",
    "        return\n",
    "    \n",
    "    print(\"üöÄ Running quick test...\")\n",
    "    result = await process_meeting(\n",
    "        audio_file_path=str(absolute_test_path),\n",
    "        user_id=\"quick_test\",\n",
    "        session_id=\"quick_session\"\n",
    "    )\n",
    "    \n",
    "    minutes = result.get(\"minutes\", \"\")\n",
    "    print(f\"‚úÖ Generated minutes ({len(minutes)} chars)\")\n",
    "    if minutes:\n",
    "        print(f\"Preview: {minutes[:200]}...\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "async def quick_stream_test():\n",
    "    \"\"\"Quick streaming test\"\"\"\n",
    "    if not absolute_test_path.exists():\n",
    "        print(\"‚ùå Test file not available\")\n",
    "        return\n",
    "    \n",
    "    print(\"üîÑ Running quick streaming test...\")\n",
    "    async for event in process_meeting_stream(\n",
    "        audio_file_path=str(absolute_test_path),\n",
    "        user_id=\"stream_test\",\n",
    "        session_id=\"stream_session\"\n",
    "    ):\n",
    "        print(f\"  {event.get('type', '')}: {event.get('message', '')}\")\n",
    "        if event.get('type') == 'complete':\n",
    "            minutes = event.get('minutes', '')\n",
    "            print(f\"‚úÖ Final result: {len(minutes)} chars\")\n",
    "            break\n",
    "\n",
    "# Functions are ready to use:\n",
    "# await quick_test()\n",
    "# await quick_stream_test()\n",
    "print(\"Quick test functions ready!\")\n",
    "print(\"  - await quick_test()\")\n",
    "print(\"  - await quick_stream_test()\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
