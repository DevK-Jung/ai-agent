"""
ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰ ì„±ëŠ¥ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ì£¼í”¼í„° ë…¸íŠ¸ë¶ ì—†ì´ë„ ì„±ëŠ¥ ë¶„ì„ì„ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ìŠ¤íƒ ë“œì–¼ë¡  ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.
CI/CD íŒŒì´í”„ë¼ì¸ì´ë‚˜ ì •ê¸° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì— í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

import sys
import os
import numpy as np
import time
import json
from typing import List, Dict, Tuple, Any
from dataclasses import dataclass
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from app.infra.ai.embedding_service import BGEEmbeddingService
from app.dependencies import get_embedding_service


@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    avg_similarity: float
    max_similarity: float
    std_similarity: float
    embedding_time_ms: float
    search_time_ms: float
    batch_speedup: float
    prefix_improvement_pct: float
    optimal_k: int
    optimal_threshold: float


class EmbeddingPerformanceAnalyzer:
    """ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰ ì„±ëŠ¥ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.embedding_service = get_embedding_service()
        self.test_passages = [
            "ë°ì´í„°ë² ì´ìŠ¤ëŠ” ì •ë³´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì €ì¥í•˜ê³  ê´€ë¦¬í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤. MariaDBëŠ” MySQLì˜ í¬í¬ë¡œ ê°œë°œëœ ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.",
            "ì¸ê³µì§€ëŠ¥ì€ ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì´ ì£¼ìš” ë°©ë²•ë¡ ì…ë‹ˆë‹¤.",
            "íŒŒì´ì¬ì€ ê°„ê²°í•˜ê³  ì½ê¸° ì‰¬ìš´ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤. ë°ì´í„° ê³¼í•™ê³¼ ì›¹ ê°œë°œì— ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤.",
            "í´ë¼ìš°ë“œ ì»´í“¨íŒ…ì€ ì¸í„°ë„·ì„ í†µí•´ ì»´í“¨íŒ… ìì›ì„ ì œê³µí•˜ëŠ” ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. AWS, Azure, GCPê°€ ëŒ€í‘œì ì…ë‹ˆë‹¤.",
            "FastAPIëŠ” í˜„ëŒ€ì ì´ê³  ë¹ ë¥¸ ì›¹ API í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ìë™ ë¬¸ì„œ ìƒì„±ê³¼ íƒ€ì… íŒíŠ¸ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.",
            "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ëŠ” ê³ ì°¨ì› ë²¡í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” íŠ¹ìˆ˜í•œ ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.",
            "ìì—°ì–´ ì²˜ë¦¬(NLP)ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ì²˜ë¦¬í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ë²ˆì—­, ìš”ì•½, ê°ì • ë¶„ì„ ë“±ì— í™œìš©ë©ë‹ˆë‹¤.",
            "ì„ë² ë”©ì€ ë‹¨ì–´ë‚˜ ë¬¸ì¥ì„ ê³ ì°¨ì› ë²¡í„°ë¡œ í‘œí˜„í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì˜ë¯¸ì  ìœ ì‚¬ì„±ì„ ìˆ˜ì¹˜ë¡œ ì¸¡ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "PostgreSQLì€ ê°•ë ¥í•œ ì˜¤í”ˆì†ŒìŠ¤ ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤. pgvector í™•ì¥ìœ¼ë¡œ ë²¡í„° ê²€ìƒ‰ì„ ì§€ì›í•©ë‹ˆë‹¤.",
            "ê²€ìƒ‰ ì—”ì§„ ìµœì í™”(SEO)ëŠ” ì›¹ì‚¬ì´íŠ¸ê°€ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë†’ì€ ìˆœìœ„ë¥¼ ì–»ë„ë¡ í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤."
        ]
        
        self.test_queries = [
            "ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬",
            "ë¨¸ì‹ ëŸ¬ë‹ ê¸°ìˆ ", 
            "ì›¹ API ê°œë°œ",
            "ë²¡í„° ê¸°ë°˜ ê²€ìƒ‰",
            "ìì—°ì–´ ì²˜ë¦¬"
        ]

    def cosine_similarity_matrix(self, queries: np.ndarray, passages: np.ndarray) -> np.ndarray:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°"""
        return np.dot(queries, passages.T)

    def get_top_k_results(self, similarity_matrix: np.ndarray, k: int) -> Tuple[np.ndarray, np.ndarray]:
        """Top-K ê²°ê³¼ ì¶”ì¶œ"""
        top_k_indices = np.argsort(-similarity_matrix, axis=1)[:, :k]
        top_k_scores = np.take_along_axis(similarity_matrix, top_k_indices, axis=1)
        return top_k_indices, top_k_scores

    def analyze_embeddings(self) -> Dict[str, Any]:
        """ì„ë² ë”© ê¸°ë³¸ ë¶„ì„"""
        print("ğŸ“Š ì„ë² ë”© ìƒì„± ë° ê¸°ë³¸ ë¶„ì„...")
        
        # Passage ì„ë² ë”© ìƒì„± (BGE-M3 ìµœì í™”)
        passage_embeddings = self.embedding_service.encode_passages(self.test_passages)
        passage_embeddings_array = np.array(passage_embeddings)
        
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embeddings = [self.embedding_service.encode_query(q) for q in self.test_queries]
        query_embeddings_array = np.array(query_embeddings)
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        similarity_matrix = self.cosine_similarity_matrix(query_embeddings_array, passage_embeddings_array)
        
        return {
            'similarity_matrix': similarity_matrix,
            'passage_embeddings': passage_embeddings_array,
            'query_embeddings': query_embeddings_array,
            'stats': {
                'avg_similarity': float(similarity_matrix.mean()),
                'max_similarity': float(similarity_matrix.max()),
                'std_similarity': float(similarity_matrix.std()),
                'min_similarity': float(similarity_matrix.min())
            }
        }

    def benchmark_performance(self) -> Dict[str, float]:
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        print("âš¡ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰...")
        
        test_texts = ["í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì…ë‹ˆë‹¤."] * 100
        
        # ë‹¨ì¼ ì„ë² ë”© ì„±ëŠ¥
        start_time = time.time()
        for text in test_texts[:10]:
            self.embedding_service.encode_passage(text)
        single_time = (time.time() - start_time) / 10
        
        # ë°°ì¹˜ ì„ë² ë”© ì„±ëŠ¥
        start_time = time.time()
        self.embedding_service.encode_passages(test_texts, batch_size=32)
        batch_time = time.time() - start_time
        
        # ê²€ìƒ‰ ì„±ëŠ¥
        query_emb = self.embedding_service.encode_query("í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬")
        passage_embs = np.random.randn(1000, 1024)  # ê°€ìƒì˜ 1000ê°œ ë¬¸ì„œ
        
        start_time = time.time()
        similarities = self.cosine_similarity_matrix(
            query_emb.reshape(1, -1), passage_embs
        )
        top_k_indices, top_k_scores = self.get_top_k_results(similarities, k=5)
        search_time = time.time() - start_time
        
        speedup = (single_time * len(test_texts)) / batch_time
        
        return {
            'single_embedding_ms': single_time * 1000,
            'batch_embedding_total_s': batch_time,
            'batch_embedding_per_doc_ms': (batch_time / len(test_texts)) * 1000,
            'search_time_ms': search_time * 1000,
            'batch_speedup': speedup
        }

    def test_prefix_effect(self) -> Dict[str, Any]:
        """BGE-M3 Prefix íš¨ê³¼ í…ŒìŠ¤íŠ¸"""
        print("ğŸ”¬ BGE-M3 Prefix íš¨ê³¼ ë¶„ì„...")
        
        # Prefix ìˆëŠ” ì„ë² ë”©
        with_prefix_passages = self.embedding_service.encode_passages(self.test_passages)
        with_prefix_queries = [self.embedding_service.encode_query(q) for q in self.test_queries]
        
        # Prefix ì—†ëŠ” ì„ë² ë”©
        without_prefix_passages = self.embedding_service.get_embeddings(self.test_passages)
        without_prefix_queries = [self.embedding_service.get_embeddings(q) for q in self.test_queries]
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        with_prefix_sim = self.cosine_similarity_matrix(
            np.array(with_prefix_queries), np.array(with_prefix_passages)
        )
        without_prefix_sim = self.cosine_similarity_matrix(
            np.array(without_prefix_queries), np.array(without_prefix_passages)
        )
        
        # ê°œì„  íš¨ê³¼ ê³„ì‚°
        improvement = (with_prefix_sim.mean() - without_prefix_sim.mean()) / without_prefix_sim.mean() * 100
        
        return {
            'with_prefix_avg': float(with_prefix_sim.mean()),
            'without_prefix_avg': float(without_prefix_sim.mean()),
            'improvement_pct': float(improvement),
            'with_prefix_max': float(with_prefix_sim.max()),
            'without_prefix_max': float(without_prefix_sim.max())
        }

    def optimize_parameters(self, similarity_matrix: np.ndarray) -> Dict[str, Any]:
        """ìµœì  íŒŒë¼ë¯¸í„° íƒìƒ‰"""
        print("ğŸ¯ ìµœì  íŒŒë¼ë¯¸í„° íƒìƒ‰...")
        
        k_values = [1, 3, 5, 10, 20]
        thresholds = [0.3, 0.5, 0.6, 0.7, 0.8]
        
        # Top-K ìµœì í™”
        best_k = 5
        best_k_score = 0
        k_results = {}
        
        for k in k_values:
            top_k_indices, top_k_scores = self.get_top_k_results(similarity_matrix, k)
            avg_top_score = top_k_scores[:, 0].mean()
            avg_all_scores = top_k_scores.mean()
            
            # ì¢…í•© ì ìˆ˜ (ìµœê³  ì ìˆ˜ 70% + ì „ì²´ ì ìˆ˜ 30%)
            combined_score = 0.7 * avg_top_score + 0.3 * avg_all_scores
            
            k_results[k] = {
                'avg_top_score': float(avg_top_score),
                'avg_all_scores': float(avg_all_scores),
                'combined_score': float(combined_score)
            }
            
            if combined_score > best_k_score:
                best_k_score = combined_score
                best_k = k
        
        # Threshold ìµœì í™”
        best_threshold = 0.6
        best_threshold_score = 0
        threshold_results = {}
        
        for threshold in thresholds:
            results_count = []
            scores_above_threshold = []
            
            for query_idx in range(similarity_matrix.shape[0]):
                query_scores = similarity_matrix[query_idx]
                valid_scores = query_scores[query_scores >= threshold]
                results_count.append(len(valid_scores))
                scores_above_threshold.extend(valid_scores)
            
            avg_count = np.mean(results_count)
            avg_score = np.mean(scores_above_threshold) if scores_above_threshold else 0
            
            # ìµœì  ê²°ê³¼ ìˆ˜ëŠ” 3-5ê°œ
            count_penalty = abs(avg_count - 4) / 4
            combined_score = avg_score * (1 - count_penalty * 0.3)
            
            threshold_results[threshold] = {
                'avg_count': float(avg_count),
                'avg_score': float(avg_score),
                'combined_score': float(combined_score)
            }
            
            if combined_score > best_threshold_score:
                best_threshold_score = combined_score
                best_threshold = threshold
        
        return {
            'optimal_k': best_k,
            'optimal_threshold': best_threshold,
            'k_analysis': k_results,
            'threshold_analysis': threshold_results
        }

    def run_full_analysis(self) -> PerformanceMetrics:
        """ì „ì²´ ì„±ëŠ¥ ë¶„ì„ ì‹¤í–‰"""
        print("ğŸš€ ì„ë² ë”© ê²€ìƒ‰ ì„±ëŠ¥ ë¶„ì„ ì‹œì‘")
        print("=" * 50)
        
        # 1. ê¸°ë³¸ ì„ë² ë”© ë¶„ì„
        embedding_results = self.analyze_embeddings()
        
        # 2. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
        performance_results = self.benchmark_performance()
        
        # 3. Prefix íš¨ê³¼ ë¶„ì„
        prefix_results = self.test_prefix_effect()
        
        # 4. íŒŒë¼ë¯¸í„° ìµœì í™”
        optimization_results = self.optimize_parameters(embedding_results['similarity_matrix'])
        
        # 5. ê²°ê³¼ ì¢…í•©
        metrics = PerformanceMetrics(
            avg_similarity=embedding_results['stats']['avg_similarity'],
            max_similarity=embedding_results['stats']['max_similarity'],
            std_similarity=embedding_results['stats']['std_similarity'],
            embedding_time_ms=performance_results['single_embedding_ms'],
            search_time_ms=performance_results['search_time_ms'],
            batch_speedup=performance_results['batch_speedup'],
            prefix_improvement_pct=prefix_results['improvement_pct'],
            optimal_k=optimization_results['optimal_k'],
            optimal_threshold=optimization_results['optimal_threshold']
        )
        
        # 6. ê²°ê³¼ ì¶œë ¥
        self.print_results(metrics, embedding_results, performance_results, 
                          prefix_results, optimization_results)
        
        return metrics

    def print_results(self, metrics: PerformanceMetrics, *result_dicts):
        """ê²°ê³¼ ì¶œë ¥"""
        embedding_results, performance_results, prefix_results, optimization_results = result_dicts
        
        print("\nğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("=" * 50)
        
        print(f"\nğŸ¯ ê²€ìƒ‰ í’ˆì§ˆ ì§€í‘œ:")
        print(f"  í‰ê·  ìœ ì‚¬ë„: {metrics.avg_similarity:.4f}")
        print(f"  ìµœëŒ€ ìœ ì‚¬ë„: {metrics.max_similarity:.4f}")
        print(f"  í‘œì¤€í¸ì°¨: {metrics.std_similarity:.4f}")
        
        print(f"\nâš¡ ì„±ëŠ¥ ì§€í‘œ:")
        print(f"  ë‹¨ì¼ ì„ë² ë”© ì‹œê°„: {metrics.embedding_time_ms:.1f}ms")
        print(f"  ê²€ìƒ‰ ì‹œê°„ (1000ê°œ ë¬¸ì„œ): {metrics.search_time_ms:.1f}ms")
        print(f"  ë°°ì¹˜ ì²˜ë¦¬ ì†ë„ í–¥ìƒ: {metrics.batch_speedup:.1f}x")
        
        print(f"\nğŸ”¬ BGE-M3 Prefix íš¨ê³¼:")
        print(f"  ì„±ëŠ¥ ê°œì„ : +{metrics.prefix_improvement_pct:.1f}%")
        print(f"  Prefix ìˆìŒ: {prefix_results['with_prefix_avg']:.4f}")
        print(f"  Prefix ì—†ìŒ: {prefix_results['without_prefix_avg']:.4f}")
        
        print(f"\nğŸ¯ ìµœì  íŒŒë¼ë¯¸í„°:")
        print(f"  Top-K: {metrics.optimal_k}")
        print(f"  Threshold: {metrics.optimal_threshold}")
        
        print(f"\nğŸ’¡ ê¶Œì¥ ì„¤ì •:")
        print(f"  - BGE-M3 Prefix: âœ… í•„ìˆ˜ ì‚¬ìš©")
        print(f"  - Top-K ê²€ìƒ‰: k={metrics.optimal_k}")
        print(f"  - Threshold: {metrics.optimal_threshold}")
        print(f"  - ë°°ì¹˜ í¬ê¸°: 32")
        
        print(f"\nğŸš€ ì˜ˆìƒ í”„ë¡œë•ì…˜ ì„±ëŠ¥:")
        print(f"  - ë‹¨ì¼ ê²€ìƒ‰ ì‘ë‹µì‹œê°„: ~{metrics.search_time_ms:.0f}ms")
        print(f"  - ë¬¸ì„œë‹¹ ì„ë² ë”© ì‹œê°„: ~{performance_results['batch_embedding_per_doc_ms']:.1f}ms")
        print(f"  - ê²€ìƒ‰ í’ˆì§ˆ: {metrics.max_similarity:.1%} (ìµœê³  ìœ ì‚¬ë„)")

    def save_results(self, metrics: PerformanceMetrics, output_path: str = None):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        if output_path is None:
            output_path = f"embedding_performance_{int(time.time())}.json"
        
        results = {
            'timestamp': time.time(),
            'model': self.embedding_service.model_name,
            'device': self.embedding_service.device,
            'metrics': {
                'avg_similarity': metrics.avg_similarity,
                'max_similarity': metrics.max_similarity,
                'std_similarity': metrics.std_similarity,
                'embedding_time_ms': metrics.embedding_time_ms,
                'search_time_ms': metrics.search_time_ms,
                'batch_speedup': metrics.batch_speedup,
                'prefix_improvement_pct': metrics.prefix_improvement_pct,
                'optimal_k': metrics.optimal_k,
                'optimal_threshold': metrics.optimal_threshold
            }
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    analyzer = EmbeddingPerformanceAnalyzer()
    
    try:
        metrics = analyzer.run_full_analysis()
        analyzer.save_results(metrics)
        
        print("\nâœ… ë¶„ì„ ì™„ë£Œ!")
        return metrics
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise


if __name__ == "__main__":
    main()