{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ìƒˆë¡œ êµ¬í˜„í•œ ë¶„ë¦¬ëœ íŒŒì„œ ì‹œìŠ¤í…œì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n",
    "- PDF íŒŒì„œ\n",
    "- DOCX íŒŒì„œ  \n",
    "- XLSX íŒŒì„œ\n",
    "- CSV íŒŒì„œ (ì¶”ê°€ êµ¬í˜„ í•„ìš”ì‹œ)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T11:57:44.824728Z",
     "start_time": "2026-02-16T11:57:44.821911Z"
    }
   },
   "source": [
    "# í™˜ê²½ ì„¤ì •\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í”„ë¡œì íŠ¸ ë£¨íŠ¸: /Users/kimjunghyeon/Desktop/workspace/ai-agent\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T11:57:48.447713Z",
     "start_time": "2026-02-16T11:57:44.887056Z"
    }
   },
   "source": [
    "# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(project_root / '.env')\n",
    "\n",
    "# Parser ì‹œìŠ¤í…œ import\n",
    "from app.infra.parsers import ParserFactory\n",
    "from app.services.document_processor import DocumentProcessor\n",
    "import asyncio"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimjunghyeon/Desktop/workspace/ai-agent/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T11:57:48.457899Z",
     "start_time": "2026-02-16T11:57:48.455354Z"
    }
   },
   "source": [
    "# í…ŒìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ í™•ì¸\n",
    "data_dir = project_root / \"data\" / \"documents\"\n",
    "print(f\"ë°ì´í„° ë””ë ‰í† ë¦¬: {data_dir}\")\n",
    "print(f\"ë””ë ‰í† ë¦¬ ì¡´ì¬: {data_dir.exists()}\")\n",
    "\n",
    "if data_dir.exists():\n",
    "    files = list(data_dir.glob(\"*\"))\n",
    "    print(f\"\\níŒŒì¼ ëª©ë¡ ({len(files)}ê°œ):\")\n",
    "    for file in files:\n",
    "        print(f\"  - {file.name} ({file.stat().st_size:,} bytes)\")\n",
    "else:\n",
    "    print(\"ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ë””ë ‰í† ë¦¬: /Users/kimjunghyeon/Desktop/workspace/ai-agent/data/documents\n",
      "ë””ë ‰í† ë¦¬ ì¡´ì¬: True\n",
      "\n",
      "íŒŒì¼ ëª©ë¡ (3ê°œ):\n",
      "  - ì†Œë“ì„¸ë²•.doc (1,965,420 bytes)\n",
      "  - ì „êµ­_ì•¼ì˜ì¥_20260106.csv (1,074,261 bytes)\n",
      "  - ì†Œë“ì„¸ë²•.pdf (794,133 bytes)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T11:57:48.466411Z",
     "start_time": "2026-02-16T11:57:48.464686Z"
    }
   },
   "source": [
    "# ì§€ì›ë˜ëŠ” íŒŒì¼ í˜•ì‹ í™•ì¸\n",
    "print(\"ì§€ì›ë˜ëŠ” MIME íƒ€ì…:\")\n",
    "for mime_type in ParserFactory.get_supported_mime_types():\n",
    "    print(f\"  - {mime_type}\")\n",
    "\n",
    "print(\"\\nì§€ì›ë˜ëŠ” íŒŒì¼ í™•ì¥ì:\")\n",
    "for ext in ParserFactory.get_supported_extensions():\n",
    "    print(f\"  - {ext}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì§€ì›ë˜ëŠ” MIME íƒ€ì…:\n",
      "  - application/pdf\n",
      "  - application/vnd.openxmlformats-officedocument.wordprocessingml.document\n",
      "  - application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\n",
      "  - text/csv\n",
      "  - application/csv\n",
      "  - application/msword\n",
      "  - application/vnd.ms-word\n",
      "\n",
      "ì§€ì›ë˜ëŠ” íŒŒì¼ í™•ì¥ì:\n",
      "  - .pdf\n",
      "  - .docx\n",
      "  - .xlsx\n",
      "  - .csv\n",
      "  - .doc\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T11:57:48.479890Z",
     "start_time": "2026-02-16T11:57:48.478177Z"
    }
   },
   "source": [
    "# MIME íƒ€ì… ë§¤í•‘\n",
    "mime_mapping = {\n",
    "    \".pdf\": \"application/pdf\",\n",
    "    \".docx\": \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\",\n",
    "    \".xlsx\": \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\",\n",
    "    \".csv\": \"text/csv\",  # CSVëŠ” ì•„ì§ ì§€ì›í•˜ì§€ ì•Šì§€ë§Œ í…ŒìŠ¤íŠ¸ìš©\n",
    "    \".txt\": \"text/plain\"\n",
    "}\n",
    "\n",
    "def get_mime_type(file_path):\n",
    "    \"\"\"íŒŒì¼ í™•ì¥ìë¡œë¶€í„° MIME íƒ€ì… ì¶”ì •\"\"\"\n",
    "    suffix = Path(file_path).suffix.lower()\n",
    "    return mime_mapping.get(suffix, \"unknown\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T11:57:48.490947Z",
     "start_time": "2026-02-16T11:57:48.487264Z"
    }
   },
   "source": [
    "# ê°œë³„ íŒŒì„œ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜\n",
    "async def test_parser(file_path, mime_type=None):\n",
    "    \"\"\"ê°œë³„ íŒŒì„œ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    if not file_path.exists():\n",
    "        print(f\"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    if mime_type is None:\n",
    "        mime_type = get_mime_type(file_path)\n",
    "    \n",
    "    print(f\"\\nğŸ“„ í…ŒìŠ¤íŠ¸: {file_path.name}\")\n",
    "    print(f\"   MIME íƒ€ì…: {mime_type}\")\n",
    "    print(f\"   íŒŒì¼ í¬ê¸°: {file_path.stat().st_size:,} bytes\")\n",
    "    \n",
    "    # ì§€ì› ì—¬ë¶€ í™•ì¸\n",
    "    if not ParserFactory.is_supported_mime_type(mime_type):\n",
    "        print(f\"   âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # íŒŒì„œ ìƒì„± ë° íŒŒì‹±\n",
    "        parser = ParserFactory.get_parser(mime_type)\n",
    "        print(f\"   ğŸ”§ íŒŒì„œ: {parser.__class__.__name__}\")\n",
    "        \n",
    "        # íŒŒì‹± ì‹¤í–‰\n",
    "        parsed_content = await parser.parse(str(file_path))\n",
    "        \n",
    "        # ê²°ê³¼ ì¶œë ¥\n",
    "        print(f\"   âœ… íŒŒì‹± ì„±ê³µ!\")\n",
    "        print(f\"   ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(parsed_content.raw_text):,} ë¬¸ì\")\n",
    "        print(f\"   ğŸ“Š í…Œì´ë¸” ìˆ˜: {len(parsed_content.tables)}ê°œ\")\n",
    "        print(f\"   ğŸ–¼ï¸ ì´ë¯¸ì§€ ìˆ˜: {len(parsed_content.images)}ê°œ\")\n",
    "        print(f\"   ğŸ“‹ ë©”íƒ€ë°ì´í„°: {len(parsed_content.metadata)}ê°œ í•­ëª©\")\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°\n",
    "        preview = parsed_content.raw_text[:300].replace('\\n', ' ').strip()\n",
    "        if len(parsed_content.raw_text) > 300:\n",
    "            preview += \"...\"\n",
    "        print(f\"   ğŸ‘€ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {preview}\")\n",
    "        \n",
    "        # í…Œì´ë¸” ì •ë³´\n",
    "        if parsed_content.tables:\n",
    "            print(f\"   ğŸ“Š í…Œì´ë¸” ìƒì„¸:\")\n",
    "            for i, table in enumerate(parsed_content.tables[:3]):  # ìµœëŒ€ 3ê°œë§Œ\n",
    "                print(f\"      - í…Œì´ë¸” {i+1}: {len(table.headers)}ì—´ x {len(table.rows)}í–‰\")\n",
    "                if table.headers:\n",
    "                    headers_preview = \", \".join(table.headers[:5])\n",
    "                    if len(table.headers) > 5:\n",
    "                        headers_preview += \"...\"\n",
    "                    print(f\"        í—¤ë”: {headers_preview}\")\n",
    "        \n",
    "        return parsed_content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
    "        return None"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T11:57:48.507222Z",
     "start_time": "2026-02-16T11:57:48.503556Z"
    }
   },
   "source": [
    "# DocumentProcessorë¥¼ í†µí•œ í…ŒìŠ¤íŠ¸\n",
    "async def test_document_processor(file_path, mime_type=None):\n",
    "    \"\"\"DocumentProcessorë¥¼ í†µí•œ í†µí•© í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    if not file_path.exists():\n",
    "        print(f\"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    if mime_type is None:\n",
    "        mime_type = get_mime_type(file_path)\n",
    "    \n",
    "    print(f\"\\nğŸ”„ DocumentProcessor í…ŒìŠ¤íŠ¸: {file_path.name}\")\n",
    "    \n",
    "    try:\n",
    "        processor = DocumentProcessor()\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "        extracted_text = await processor.extract_text_from_file(str(file_path), mime_type)\n",
    "        print(f\"   âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ!\")\n",
    "        print(f\"   ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(extracted_text):,} ë¬¸ì\")\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ ìœ íš¨ì„± ê²€ì¦\n",
    "        is_valid = processor.validate_file_content(extracted_text)\n",
    "        print(f\"   ğŸ” í…ìŠ¤íŠ¸ ìœ íš¨ì„±: {'âœ… ìœ íš¨' if is_valid else 'âŒ ë¬´íš¨'}\")\n",
    "        \n",
    "        # ì²­í‚¹ í…ŒìŠ¤íŠ¸\n",
    "        if is_valid:\n",
    "            chunks = processor.chunk_text(extracted_text, {\"file_name\": file_path.name})\n",
    "            print(f\"   ğŸ§© ì²­í‚¹ ê²°ê³¼: {len(chunks)}ê°œ ì²­í¬\")\n",
    "            \n",
    "            if chunks:\n",
    "                avg_size = sum(chunk['char_count'] for chunk in chunks) / len(chunks)\n",
    "                avg_tokens = sum(chunk['token_count'] for chunk in chunks) / len(chunks)\n",
    "                print(f\"   ğŸ“Š í‰ê·  ì²­í¬ í¬ê¸°: {avg_size:.0f}ë¬¸ì, {avg_tokens:.0f}í† í°\")\n",
    "                \n",
    "                # ì²« ë²ˆì§¸ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°\n",
    "                first_chunk_preview = chunks[0]['content'][:200].replace('\\n', ' ').strip()\n",
    "                if len(chunks[0]['content']) > 200:\n",
    "                    first_chunk_preview += \"...\"\n",
    "                print(f\"   ğŸ‘€ ì²« ì²­í¬ ë¯¸ë¦¬ë³´ê¸°: {first_chunk_preview}\")\n",
    "        \n",
    "        return extracted_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ DocumentProcessor ì‹¤íŒ¨: {e}\")\n",
    "        return None"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T11:57:58.143351Z",
     "start_time": "2026-02-16T11:57:48.512907Z"
    }
   },
   "source": [
    "# ëª¨ë“  íŒŒì¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "async def test_all_files():\n",
    "    \"\"\"ë°ì´í„° ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  íŒŒì¼ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    if not data_dir.exists():\n",
    "        print(\"ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        return\n",
    "    \n",
    "    files = [f for f in data_dir.glob(\"*\") if f.is_file()]\n",
    "    print(f\"ğŸš€ ì´ {len(files)}ê°œ íŒŒì¼ í…ŒìŠ¤íŠ¸ ì‹œì‘\\n\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for file_path in files:\n",
    "        mime_type = get_mime_type(file_path)\n",
    "        \n",
    "        # ê°œë³„ íŒŒì„œ í…ŒìŠ¤íŠ¸\n",
    "        parsed_result = await test_parser(file_path, mime_type)\n",
    "        \n",
    "        # DocumentProcessor í…ŒìŠ¤íŠ¸\n",
    "        processor_result = await test_document_processor(file_path, mime_type)\n",
    "        \n",
    "        results[file_path.name] = {\n",
    "            'parsed': parsed_result is not None,\n",
    "            'processed': processor_result is not None,\n",
    "            'mime_type': mime_type\n",
    "        }\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # ê²°ê³¼ ìš”ì•½\n",
    "    print(\"\\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    success_count = 0\n",
    "    for filename, result in results.items():\n",
    "        status = \"âœ… ì„±ê³µ\" if result['processed'] else \"âŒ ì‹¤íŒ¨\"\n",
    "        if result['processed']:\n",
    "            success_count += 1\n",
    "        print(f\"{filename:<30} {result['mime_type']:<15} {status}\")\n",
    "    \n",
    "    print(f\"\\nì„±ê³µë¥ : {success_count}/{len(files)} ({success_count/len(files)*100:.1f}%)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "test_results = await test_all_files()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ (/Users/kimjunghyeon/Desktop/workspace/ai-agent/data/documents/ì†Œë“ì„¸ë²•.doc): ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: unknown\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì´ 3ê°œ íŒŒì¼ í…ŒìŠ¤íŠ¸ ì‹œì‘\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“„ í…ŒìŠ¤íŠ¸: ì†Œë“ì„¸ë²•.doc\n",
      "   MIME íƒ€ì…: unknown\n",
      "   íŒŒì¼ í¬ê¸°: 1,965,420 bytes\n",
      "   âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ”„ DocumentProcessor í…ŒìŠ¤íŠ¸: ì†Œë“ì„¸ë²•.doc\n",
      "   âŒ DocumentProcessor ì‹¤íŒ¨: ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: unknown\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“„ í…ŒìŠ¤íŠ¸: ì „êµ­_ì•¼ì˜ì¥_20260106.csv\n",
      "   MIME íƒ€ì…: text/csv\n",
      "   íŒŒì¼ í¬ê¸°: 1,074,261 bytes\n",
      "   ğŸ”§ íŒŒì„œ: CSVParser\n",
      "   âœ… íŒŒì‹± ì„±ê³µ!\n",
      "   ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´: 21,868 ë¬¸ì\n",
      "   ğŸ“Š í…Œì´ë¸” ìˆ˜: 1ê°œ\n",
      "   ğŸ–¼ï¸ ì´ë¯¸ì§€ ìˆ˜: 0ê°œ\n",
      "   ğŸ“‹ ë©”íƒ€ë°ì´í„°: 5ê°œ í•­ëª©\n",
      "   ğŸ‘€ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: ë²ˆí˜¸ | ì•¼ì˜ì¥ëª… | ì‚¬ì—…ì£¼ì²´_êµ¬ë¶„ | ë„ | ì‹œêµ°êµ¬ | ì£¼ì†Œ | ì£¼ìš”ì‹œì„¤ ì¼ë°˜ì•¼ì˜ì¥ | ì£¼ìš”ì‹œì„¤ ìë™ì°¨ì•¼ì˜ì¥ | ì£¼ìš”ì‹œì„¤ ê¸€ë¨í•‘ | ì£¼ìš”ì‹œì„¤ ì¹´ë¼ë°˜ | ì£¼ìš”ì‹œì„¤ ê°œì¸ ì¹´ë¼ë°˜ | ì£¼ìš”ì‹œì„¤ ë¤í”„ìŠ¤í…Œì´ì…˜ | ì‚¬ì´íŠ¸ í¬ê¸°1 ê°€ë¡œ | ì‚¬ì´íŠ¸ í¬ê¸°2 ê°€ë¡œ | ì‚¬ì´íŠ¸ í¬ê¸°3 ê°€ë¡œ | ì‚¬ì´íŠ¸ í¬ê¸°1 ì„¸ë¡œ | ì‚¬ì´íŠ¸ í¬ê¸°2 ì„¸ë¡œ | ì‚¬ì´íŠ¸ í¬ê¸°3 ì„¸ë¡œ | ì‚¬ì´íŠ¸ í¬ê¸°1 ìˆ˜ëŸ‰ | ì‚¬ì´íŠ¸ í¬ê¸°2 ìˆ˜ëŸ‰ | ì‚¬ì´íŠ¸ í¬ê¸°3 ìˆ˜ëŸ‰ | ì¸í—ˆê°€ì¼ì | í™”ë¡œëŒ€ | ë¶€ëŒ€ì‹œì„¤ | ì£¼ë³€ì´ìš©ê°€ëŠ¥ì‹œì„¤ | ì†Œí™”ê¸° ê°œìˆ˜ | ë°©í™”ìˆ˜ ê°œìˆ˜ | ë°©í™”ì‚¬ ê°œìˆ˜ | í™”ì¬ê°ì§€ê¸° ê°œìˆ˜ |...\n",
      "   ğŸ“Š í…Œì´ë¸” ìƒì„¸:\n",
      "      - í…Œì´ë¸” 1: 32ì—´ x 5106í–‰\n",
      "        í—¤ë”: ë²ˆí˜¸, ì•¼ì˜ì¥ëª…, ì‚¬ì—…ì£¼ì²´_êµ¬ë¶„, ë„, ì‹œêµ°êµ¬...\n",
      "\n",
      "ğŸ”„ DocumentProcessor í…ŒìŠ¤íŠ¸: ì „êµ­_ì•¼ì˜ì¥_20260106.csv\n",
      "   âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ!\n",
      "   ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: 21,868 ë¬¸ì\n",
      "   ğŸ” í…ìŠ¤íŠ¸ ìœ íš¨ì„±: âœ… ìœ íš¨\n",
      "   ğŸ§© ì²­í‚¹ ê²°ê³¼: 25ê°œ ì²­í¬\n",
      "   ğŸ“Š í‰ê·  ì²­í¬ í¬ê¸°: 970ë¬¸ì, 539í† í°\n",
      "   ğŸ‘€ ì²« ì²­í¬ ë¯¸ë¦¬ë³´ê¸°: ë²ˆí˜¸ | ì•¼ì˜ì¥ëª… | ì‚¬ì—…ì£¼ì²´_êµ¬ë¶„ | ë„ | ì‹œêµ°êµ¬ | ì£¼ì†Œ | ì£¼ìš”ì‹œì„¤ ì¼ë°˜ì•¼ì˜ì¥ | ì£¼ìš”ì‹œì„¤ ìë™ì°¨ì•¼ì˜ì¥ | ì£¼ìš”ì‹œì„¤ ê¸€ë¨í•‘ | ì£¼ìš”ì‹œì„¤ ì¹´ë¼ë°˜ | ì£¼ìš”ì‹œì„¤ ê°œì¸ ì¹´ë¼ë°˜ | ì£¼ìš”ì‹œì„¤ ë¤í”„ìŠ¤í…Œì´ì…˜ | ì‚¬ì´íŠ¸ í¬ê¸°1 ê°€ë¡œ | ì‚¬ì´íŠ¸ í¬ê¸°2 ê°€ë¡œ | ì‚¬ì´íŠ¸ í¬ê¸°3 ê°€ë¡œ | ì‚¬ì´íŠ¸ í¬ê¸°1 ì„¸ë¡œ | ì‚¬ì´íŠ¸ í¬ê¸°2 ì„¸ë¡œ | ì‚¬ì´íŠ¸ í¬ê¸°3 ì„¸ë¡œ | ì‚¬ì´íŠ¸ í¬ê¸°1...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“„ í…ŒìŠ¤íŠ¸: ì†Œë“ì„¸ë²•.pdf\n",
      "   MIME íƒ€ì…: application/pdf\n",
      "   íŒŒì¼ í¬ê¸°: 794,133 bytes\n",
      "   ğŸ”§ íŒŒì„œ: PDFParser\n",
      "Consider using the pymupdf_layout package for a greatly improved page layout analysis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyMuPDF íŒŒì‹± ì‹¤íŒ¨: PyMuPDF PDF íŒŒì‹± ì‹¤íŒ¨: document closed. PyPDF2ë¡œ fallbackí•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… íŒŒì‹± ì„±ê³µ!\n",
      "   ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´: 271,032 ë¬¸ì\n",
      "   ğŸ“Š í…Œì´ë¸” ìˆ˜: 0ê°œ\n",
      "   ğŸ–¼ï¸ ì´ë¯¸ì§€ ìˆ˜: 0ê°œ\n",
      "   ğŸ“‹ ë©”íƒ€ë°ì´í„°: 6ê°œ í•­ëª©\n",
      "   ğŸ‘€ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: [í˜ì´ì§€ 1] ë²•ì œì²˜                                                            1                                                       êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° ì†Œë“ì„¸ë²•    ì†Œë“ì„¸ë²•  [ì‹œí–‰ 2026. 1. 2.] [ë²•ë¥  ì œ21065í˜¸, 2025. 10. 1., íƒ€ë²•ê°œì •]  ì¬ì •ê²½ì œë¶€ (ì¬ì‚°ì„¸ì œê³¼(ì–‘ë„ì†Œë“ì„¸)) 044-215-4312  ì¬ì •ê²½ì œë¶€ (ì†Œë“ì„¸ì œê³¼(ê·¼ë¡œì†Œë“)) 044-215-4216  ì¬ì •ê²½ì œë¶€ (ê¸ˆìœµì„¸ì œê³¼(ì´ìì†Œë“, ë°°ë‹¹ì†Œë“)) 044-...\n",
      "\n",
      "ğŸ”„ DocumentProcessor í…ŒìŠ¤íŠ¸: ì†Œë“ì„¸ë²•.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyMuPDF íŒŒì‹± ì‹¤íŒ¨: PyMuPDF PDF íŒŒì‹± ì‹¤íŒ¨: document closed. PyPDF2ë¡œ fallbackí•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ!\n",
      "   ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: 271,032 ë¬¸ì\n",
      "   ğŸ” í…ìŠ¤íŠ¸ ìœ íš¨ì„±: âœ… ìœ íš¨\n",
      "   ğŸ§© ì²­í‚¹ ê²°ê³¼: 302ê°œ ì²­í¬\n",
      "   ğŸ“Š í‰ê·  ì²­í¬ í¬ê¸°: 993ë¬¸ì, 548í† í°\n",
      "   ğŸ‘€ ì²« ì²­í¬ ë¯¸ë¦¬ë³´ê¸°: [í˜ì´ì§€ 1] ë²•ì œì²˜                                                            1                                                       êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° ì†Œë“ì„¸ë²•    ì†Œë“ì„¸ë²•  [ì‹œí–‰ 2026. 1. 2.] [ë²•ë¥  ì œ21065í˜¸, 2025. 10. 1., íƒ€ë²•ê°œì •]...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:\n",
      "------------------------------------------------------------\n",
      "ì†Œë“ì„¸ë²•.doc                       unknown         âŒ ì‹¤íŒ¨\n",
      "ì „êµ­_ì•¼ì˜ì¥_20260106.csv            text/csv        âœ… ì„±ê³µ\n",
      "ì†Œë“ì„¸ë²•.pdf                       application/pdf âœ… ì„±ê³µ\n",
      "\n",
      "ì„±ê³µë¥ : 2/3 (66.7%)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T11:57:58.156766Z",
     "start_time": "2026-02-16T11:57:58.152717Z"
    }
   },
   "source": [
    "# CSV íŒŒì¼ì„ ìœ„í•œ ê°„ë‹¨í•œ íŒŒì„œ (í•„ìš”í•œ ê²½ìš°)\n",
    "# CSVëŠ” ê¸°ë³¸ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ê°„ë‹¨íˆ í…ìŠ¤íŠ¸ë¡œ ì½ì–´ë³´ê¸°\n",
    "\n",
    "def test_csv_file_simple(file_path):\n",
    "    \"\"\"CSV íŒŒì¼ ê°„ë‹¨ í…ŒìŠ¤íŠ¸ (í…ìŠ¤íŠ¸ë¡œ ì½ê¸°)\"\"\"\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        \n",
    "        print(f\"\\nğŸ“Š CSV íŒŒì¼ í…ŒìŠ¤íŠ¸: {Path(file_path).name}\")\n",
    "        \n",
    "        # pandasë¡œ ì½ê¸°\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"   ğŸ“ í˜•íƒœ: {df.shape[0]}í–‰ x {df.shape[1]}ì—´\")\n",
    "        print(f\"   ğŸ“‹ ì»¬ëŸ¼: {list(df.columns[:5])}...\" if len(df.columns) > 5 else f\"   ğŸ“‹ ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "        text_content = df.to_string(max_rows=20)\n",
    "        print(f\"   ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text_content):,} ë¬¸ì\")\n",
    "        \n",
    "        # ë¯¸ë¦¬ë³´ê¸°\n",
    "        print(f\"   ğŸ‘€ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "        print(df.head(3).to_string())\n",
    "        \n",
    "        return text_content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ CSV í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# CSV íŒŒì¼ ì°¾ì•„ì„œ í…ŒìŠ¤íŠ¸\n",
    "csv_files = list(data_dir.glob(\"*.csv\"))\n",
    "if csv_files:\n",
    "    for csv_file in csv_files:\n",
    "        test_csv_file_simple(csv_file)\n",
    "else:\n",
    "    print(\"CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š CSV íŒŒì¼ í…ŒìŠ¤íŠ¸: ì „êµ­_ì•¼ì˜ì¥_20260106.csv\n",
      "   âŒ CSV í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: 'utf-8' codec can't decode byte 0xb9 in position 0: invalid start byte\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T11:57:58.193828Z",
     "start_time": "2026-02-16T11:57:58.170383Z"
    }
   },
   "source": [
    "# íŠ¹ì • íŒŒì¼ ìƒì„¸ ë¶„ì„ (ì„ íƒì‚¬í•­)\n",
    "# í…ŒìŠ¤íŠ¸ ê²°ê³¼ì—ì„œ ì„±ê³µí•œ íŒŒì¼ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ ìƒì„¸ ë¶„ì„\n",
    "\n",
    "async def detailed_analysis(file_path):\n",
    "    \"\"\"íŠ¹ì • íŒŒì¼ì˜ ìƒì„¸ ë¶„ì„\"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    mime_type = get_mime_type(file_path)\n",
    "    \n",
    "    print(f\"\\nğŸ” ìƒì„¸ ë¶„ì„: {file_path.name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if ParserFactory.is_supported_mime_type(mime_type):\n",
    "        parser = ParserFactory.get_parser(mime_type)\n",
    "        parsed_content = await parser.parse(str(file_path))\n",
    "        \n",
    "        print(f\"ğŸ“‹ ë©”íƒ€ë°ì´í„° ìƒì„¸:\")\n",
    "        for key, value in parsed_content.metadata.items():\n",
    "            print(f\"   {key}: {value}\")\n",
    "        \n",
    "        print(f\"\\nğŸ—ï¸ êµ¬ì¡° ì •ë³´:\")\n",
    "        for key, value in parsed_content.structure.items():\n",
    "            print(f\"   {key}: {value}\")\n",
    "        \n",
    "        if parsed_content.tables:\n",
    "            print(f\"\\nğŸ“Š í…Œì´ë¸” ìƒì„¸ ì •ë³´:\")\n",
    "            for i, table in enumerate(parsed_content.tables):\n",
    "                print(f\"   í…Œì´ë¸” {i+1}:\")\n",
    "                print(f\"     - í¬ê¸°: {len(table.headers)}ì—´ x {len(table.rows)}í–‰\")\n",
    "                print(f\"     - í—¤ë”: {table.headers}\")\n",
    "                print(f\"     - ìœ„ì¹˜: {table.position}\")\n",
    "                print(f\"     - ë©”íƒ€ë°ì´í„°: {table.metadata}\")\n",
    "                if table.rows:\n",
    "                    print(f\"     - ì²« ë²ˆì§¸ í–‰: {table.rows[0]}\")\n",
    "                print()\n",
    "        \n",
    "        return parsed_content\n",
    "    else:\n",
    "        print(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {mime_type}\")\n",
    "        return None\n",
    "\n",
    "# ì„±ê³µí•œ íŒŒì¼ ì¤‘ ì²« ë²ˆì§¸ íŒŒì¼ë¡œ ìƒì„¸ ë¶„ì„ (ìˆëŠ” ê²½ìš°)\n",
    "if test_results:\n",
    "    successful_files = [filename for filename, result in test_results.items() if result['processed']]\n",
    "    if successful_files:\n",
    "        selected_file = data_dir / successful_files[0]\n",
    "        await detailed_analysis(selected_file)\n",
    "    else:\n",
    "        print(\"ì„±ê³µì ìœ¼ë¡œ íŒŒì‹±ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” ìƒì„¸ ë¶„ì„: ì „êµ­_ì•¼ì˜ì¥_20260106.csv\n",
      "==================================================\n",
      "ğŸ“‹ ë©”íƒ€ë°ì´í„° ìƒì„¸:\n",
      "   parser: csv_parser\n",
      "   encoding: utf-8\n",
      "   total_rows: 5106\n",
      "   total_columns: 32\n",
      "   file_size: 753078\n",
      "\n",
      "ğŸ—ï¸ êµ¬ì¡° ì •ë³´:\n",
      "   total_rows: 5106\n",
      "   total_columns: 32\n",
      "   headers: ['ë²ˆí˜¸', 'ì•¼ì˜ì¥ëª…', 'ì‚¬ì—…ì£¼ì²´_êµ¬ë¶„', 'ë„', 'ì‹œêµ°êµ¬', 'ì£¼ì†Œ', 'ì£¼ìš”ì‹œì„¤ ì¼ë°˜ì•¼ì˜ì¥', 'ì£¼ìš”ì‹œì„¤ ìë™ì°¨ì•¼ì˜ì¥', 'ì£¼ìš”ì‹œì„¤ ê¸€ë¨í•‘', 'ì£¼ìš”ì‹œì„¤ ì¹´ë¼ë°˜', 'ì£¼ìš”ì‹œì„¤ ê°œì¸ ì¹´ë¼ë°˜', 'ì£¼ìš”ì‹œì„¤ ë¤í”„ìŠ¤í…Œì´ì…˜', 'ì‚¬ì´íŠ¸ í¬ê¸°1 ê°€ë¡œ', 'ì‚¬ì´íŠ¸ í¬ê¸°2 ê°€ë¡œ', 'ì‚¬ì´íŠ¸ í¬ê¸°3 ê°€ë¡œ', 'ì‚¬ì´íŠ¸ í¬ê¸°1 ì„¸ë¡œ', 'ì‚¬ì´íŠ¸ í¬ê¸°2 ì„¸ë¡œ', 'ì‚¬ì´íŠ¸ í¬ê¸°3 ì„¸ë¡œ', 'ì‚¬ì´íŠ¸ í¬ê¸°1 ìˆ˜ëŸ‰', 'ì‚¬ì´íŠ¸ í¬ê¸°2 ìˆ˜ëŸ‰', 'ì‚¬ì´íŠ¸ í¬ê¸°3 ìˆ˜ëŸ‰', 'ì¸í—ˆê°€ì¼ì', 'í™”ë¡œëŒ€', 'ë¶€ëŒ€ì‹œì„¤', 'ì£¼ë³€ì´ìš©ê°€ëŠ¥ì‹œì„¤', 'ì†Œí™”ê¸° ê°œìˆ˜', 'ë°©í™”ìˆ˜ ê°œìˆ˜', 'ë°©í™”ì‚¬ ê°œìˆ˜', 'í™”ì¬ê°ì§€ê¸° ê°œìˆ˜', 'í…Œë§ˆí™˜ê²½', 'ìº í•‘ì¥ë¹„ëŒ€ì—¬', 'ë°˜ë ¤ë™ë¬¼ì¶œì…']\n",
      "   data_types: {'ë²ˆí˜¸': 'numeric', 'ì•¼ì˜ì¥ëª…': 'text', 'ì‚¬ì—…ì£¼ì²´_êµ¬ë¶„': 'text', 'ë„': 'text', 'ì‹œêµ°êµ¬': 'text', 'ì£¼ì†Œ': 'date', 'ì£¼ìš”ì‹œì„¤ ì¼ë°˜ì•¼ì˜ì¥': 'numeric', 'ì£¼ìš”ì‹œì„¤ ìë™ì°¨ì•¼ì˜ì¥': 'numeric', 'ì£¼ìš”ì‹œì„¤ ê¸€ë¨í•‘': 'numeric', 'ì£¼ìš”ì‹œì„¤ ì¹´ë¼ë°˜': 'numeric', 'ì£¼ìš”ì‹œì„¤ ê°œì¸ ì¹´ë¼ë°˜': 'numeric', 'ì£¼ìš”ì‹œì„¤ ë¤í”„ìŠ¤í…Œì´ì…˜': 'numeric', 'ì‚¬ì´íŠ¸ í¬ê¸°1 ê°€ë¡œ': 'numeric', 'ì‚¬ì´íŠ¸ í¬ê¸°2 ê°€ë¡œ': 'numeric', 'ì‚¬ì´íŠ¸ í¬ê¸°3 ê°€ë¡œ': 'numeric', 'ì‚¬ì´íŠ¸ í¬ê¸°1 ì„¸ë¡œ': 'numeric', 'ì‚¬ì´íŠ¸ í¬ê¸°2 ì„¸ë¡œ': 'numeric', 'ì‚¬ì´íŠ¸ í¬ê¸°3 ì„¸ë¡œ': 'numeric', 'ì‚¬ì´íŠ¸ í¬ê¸°1 ìˆ˜ëŸ‰': 'numeric', 'ì‚¬ì´íŠ¸ í¬ê¸°2 ìˆ˜ëŸ‰': 'numeric', 'ì‚¬ì´íŠ¸ í¬ê¸°3 ìˆ˜ëŸ‰': 'numeric', 'ì¸í—ˆê°€ì¼ì': 'date', 'í™”ë¡œëŒ€': 'text', 'ë¶€ëŒ€ì‹œì„¤': 'text', 'ì£¼ë³€ì´ìš©ê°€ëŠ¥ì‹œì„¤': 'text', 'ì†Œí™”ê¸° ê°œìˆ˜': 'numeric', 'ë°©í™”ìˆ˜ ê°œìˆ˜': 'numeric', 'ë°©í™”ì‚¬ ê°œìˆ˜': 'numeric', 'í™”ì¬ê°ì§€ê¸° ê°œìˆ˜': 'numeric', 'í…Œë§ˆí™˜ê²½': 'text', 'ìº í•‘ì¥ë¹„ëŒ€ì—¬': 'text', 'ë°˜ë ¤ë™ë¬¼ì¶œì…': 'text'}\n",
      "\n",
      "ğŸ“Š í…Œì´ë¸” ìƒì„¸ ì •ë³´:\n",
      "   í…Œì´ë¸” 1:\n",
      "     - í¬ê¸°: 32ì—´ x 5106í–‰\n",
      "     - í—¤ë”: ['ë²ˆí˜¸', 'ì•¼ì˜ì¥ëª…', 'ì‚¬ì—…ì£¼ì²´_êµ¬ë¶„', 'ë„', 'ì‹œêµ°êµ¬', 'ì£¼ì†Œ', 'ì£¼ìš”ì‹œì„¤ ì¼ë°˜ì•¼ì˜ì¥', 'ì£¼ìš”ì‹œì„¤ ìë™ì°¨ì•¼ì˜ì¥', 'ì£¼ìš”ì‹œì„¤ ê¸€ë¨í•‘', 'ì£¼ìš”ì‹œì„¤ ì¹´ë¼ë°˜', 'ì£¼ìš”ì‹œì„¤ ê°œì¸ ì¹´ë¼ë°˜', 'ì£¼ìš”ì‹œì„¤ ë¤í”„ìŠ¤í…Œì´ì…˜', 'ì‚¬ì´íŠ¸ í¬ê¸°1 ê°€ë¡œ', 'ì‚¬ì´íŠ¸ í¬ê¸°2 ê°€ë¡œ', 'ì‚¬ì´íŠ¸ í¬ê¸°3 ê°€ë¡œ', 'ì‚¬ì´íŠ¸ í¬ê¸°1 ì„¸ë¡œ', 'ì‚¬ì´íŠ¸ í¬ê¸°2 ì„¸ë¡œ', 'ì‚¬ì´íŠ¸ í¬ê¸°3 ì„¸ë¡œ', 'ì‚¬ì´íŠ¸ í¬ê¸°1 ìˆ˜ëŸ‰', 'ì‚¬ì´íŠ¸ í¬ê¸°2 ìˆ˜ëŸ‰', 'ì‚¬ì´íŠ¸ í¬ê¸°3 ìˆ˜ëŸ‰', 'ì¸í—ˆê°€ì¼ì', 'í™”ë¡œëŒ€', 'ë¶€ëŒ€ì‹œì„¤', 'ì£¼ë³€ì´ìš©ê°€ëŠ¥ì‹œì„¤', 'ì†Œí™”ê¸° ê°œìˆ˜', 'ë°©í™”ìˆ˜ ê°œìˆ˜', 'ë°©í™”ì‚¬ ê°œìˆ˜', 'í™”ì¬ê°ì§€ê¸° ê°œìˆ˜', 'í…Œë§ˆí™˜ê²½', 'ìº í•‘ì¥ë¹„ëŒ€ì—¬', 'ë°˜ë ¤ë™ë¬¼ì¶œì…']\n",
      "     - ìœ„ì¹˜: {'file': '/Users/kimjunghyeon/Desktop/workspace/ai-agent/data/documents/ì „êµ­_ì•¼ì˜ì¥_20260106.csv'}\n",
      "     - ë©”íƒ€ë°ì´í„°: {'extraction_method': 'csv_parser', 'total_rows': 5106, 'total_columns': 32, 'file_name': 'ì „êµ­_ì•¼ì˜ì¥_20260106.csv'}\n",
      "     - ì²« ë²ˆì§¸ í–‰: ['1', 'ë°ì¼ë¦¬ëœë“œ', 'ë¯¼ê°„', 'ê°•ì›ë„', 'ì¶˜ì²œì‹œ', 'ê°•ì› ì¶˜ì²œì‹œ ë™ì‚°ë©´ ìœ—ì„±ê³¨ê¸¸ 36', '0', '14', '0', '0', '0', '0', '7', '0', '0', '8', '0', '0', '12', '0', '0', '2015-09-08', 'ê°œë³„', 'ì „ê¸°,ë¬´ì„ ì¸í„°ë„·,ì¥ì‘íŒë§¤,ì˜¨ìˆ˜,ë¬¼ë†€ì´ì¥,ë§ˆíŠ¸.í¸ì˜ì ', '', '8', '1', '2', '4', '', 'í™”ë¡œëŒ€', 'ë¶ˆê°€ëŠ¥']\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
